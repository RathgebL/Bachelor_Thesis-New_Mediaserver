\documentclass[12pt,a4paper]{report}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[german]{babel}
\usepackage{minted}
\usepackage{csquotes}
\usepackage{graphicx}
\usepackage[colorlinks=true, linkcolor=blue, urlcolor=cyan]{hyperref}
\usepackage[backend=biber,style=authoryear]{biblatex}
\usepackage[printonlyused]{acronym}

\addbibresource{bibliography.bib}

\begin{document}

% ------ Titelblatt ------
\begin{titlepage}
    \centering
    {\Large Hochschule für Musik Karlsruhe \\[1em]}
    {\large Institut für Musikinformatik und Musikwissenschaft \\[6em]}

    {\Large \textbf{Bachelorarbeit} \\[2em]}

    {\LARGE \textbf{Neuer Medienservers für die Bibliothek der Hochschule für Musik Karlsruhe} \\[6em]}

    \begin{minipage}{0.9\textwidth}
        \raggedright
        \textbf{Autor:} Lennart Rathgeb \\
        \textbf{Matrikelnummer:} 13883 \\
        \textbf{Adresse:} Insterburger Straße 2, 76139 Karlsruhe \\
        \textbf{Studiengang:} Musikinformatik (HF), Musikwissenschaft (EF) \\
        \textbf{Erstleser:} Prof. Dr. Christoph Seibert \\
        \textbf{Zweitleser:} Daniel Höpfner \\
    \end{minipage}

    \vfill
    Karlsruhe, den \today
\end{titlepage}

% ------ Inhaltsverzeichnis ------
\cleardoublepage
\pagenumbering{roman}
\tableofcontents

% ------ Abbildungsverzeichnis ------
\cleardoublepage
\listoffigures
\addcontentsline{toc}{chapter}{Abbildungsverzeichnis}
% \listoftables
% \addcontentsline{toc}{chapter}{Tabellenverzeichnis}

% ------ Abkürzungsverzeichnis ------
\chapter*{Abkürzungsverzeichnis}
\begin{acronym}[WWW] % längste Abkürzung für Einrückung
  \acro{AAC}{Advanced Audio Coding}
  \acro{ACL}{Access Control List}
  \acro{API}{Application Programming Interface}
  \acro{ARPANET}{Advanced Research Projects Agency Network}
  \acro{AVC}{Advanced Video Coding}
  \acro{CD}{Compact Disc}
  \acro{CDN}{Content Delivery Network}
  \acro{CPU}{Central Processing Unit}
  \acro{DLNA}{Digital Living Network Alliance}
  \acro{DNS}{Domain Name System}
  \acro{DRM}{Digital Rights Management}
  \acro{FEC}{Forward Error Correction}
  \acro{FLAC}{Free Lossless Audio Codec}
  \acro{GID}{Group ID}
  \acro{GPL}{GNU General Public License}
  \acro{HfM}{Hochschule für Musik}
  \acro{HDD}{Hard Disk Drive}
  \acro{HLS}{HTTP Live Streaming}
  \acro{HTTP}{Hypertext Transfer Protocol}
  \acro{HTTPS}{Hypertext Transfer Protocol Secure}
  \acro{ID3}{identifiziere eine MP3}
  \acro{IDS}{Intrusion Detection System}
  \acro{IP}{Internet Protocol}
  \acro{IPS}{Intrusion Prevention System}
  \acro{IT}{Informationstechnologie}
  \acro{KVM}{Kernel-based Virtual Machine}
  \acro{MARCXML}{Machine-Readable Cataloging in XML}
  \acro{MD5}{Message Digest Algorithm 5}
  \acro{METS}{Metadata Encoding and Transmission Standard}
  \acro{MKV}{Matroska Multimedia Container Format}
  \acro{MODS}{Metadata Object Description Schema}
  \acro{MP3}{MPEG-1/2 Audio Layer III}
  \acro{MP4}{MPEG-4 Part 14}
  \acro{MPEG-DASH}{Dynamic Adaptive Streaming over HTTP}
  \acro{NAS}{Network Attached Storage}
  \acro{NDSA}{National Digital Stewardship Alliance}
  \acro{NFS}{Network File System}
  \acro{PC}{Personal Computer}
  \acro{PDF}{Portable Document Format}
  \acro{PERSIST}{Platform to Enhance the Sustainability of the Information Society Transglobally}
  \acro{QoS}{Quality of Service}
  \acro{RAID}{Redundant Array of Independent Disks}
  \acro{RAM}{Random Access Memory}
  \acro{RBAC}{Role-Based Access Control}
  \acro{RTP}{Real-time Transport Protocol}
  \acro{RTSP}{Real-Time Streaming Protocol}
  \acro{SAN}{Storage Area Network}
  \acro{SHA-256}{Secure Hash Algorithm 256}
  \acro{SMB}{Server Message Block}
  \acro{SSD}{Solid State Drive}
  \acro{SSH}{Secure Shell}
  \acro{SSL}{Secure Sockets Layer}
  \acro{SWB}{Südwestdeutscher Bibliotheksverbund}
  \acro{TCP}{Transmission Control Protocol}
  \acro{TLS}{Transport Layer Security}
  \acro{UDP}{User Datagram Protocol}
  \acro{UNESCO}{United Nations Educational, Scientific and Cultural Organization}
  \acro{UNIX}{Uniplexed Information and Computing System}
  \acro{UID}{User ID}
  \acro{UrhG}{Urheberrechtsgesetz}
  \acro{VPN}{Virtual Private Network}
  \acro{WAV}{Waveform Audio File Format}
\end{acronym}

% ------ Einleitung ------
\cleardoublepage
\pagenumbering{arabic}
\setcounter{page}{1}
\chapter*{Einleitung}
\addcontentsline{toc}{chapter}{Einleitung}
\setcounter{section}{0}
\renewcommand\thesection{\arabic{section}}

In der Vergangenheit gab es bereits mehrere Projekte, die darauf abzielten, einen Medienserver für die Bibliothek der Hochschule für Musik Karlsruhe aufzubauen. 
Ein erster Server wurde eingerichtet, verfügte jedoch nur über eingeschränkte Funktionalität. 
Deshalb entwickelte Frederik Schroff im Jahr 2015 im Rahmen seiner Masterarbeit eine verbesserte Version mit Datenbankanbindung, 
die jedoch seit einigen Jahren nicht mehr in Betrieb ist.  

Während meiner Tätigkeit als Tutor in der Bibliothek bestand meine offizielle Aufgabe zunächst darin, CDs einzulesen, zu benennen und abzuspeichern. 
Da diese Dateien jedoch anschließend nicht abrufbar waren, begann ich, den Arbeitsprozess zu hinterfragen. 
Im Rahmen einer Praxisarbeit verbesserte ich den Digitalisierungsprozess bereits durch die Erneuerung des verwendeten Skripts. 
Nun soll ein neuer Medienserver implementiert werden, damit die bereits digitalisierten Daten auch tatsächlich genutzt werden können.  

Ziel ist es, den Server so zu gestalten, dass er leicht zu administrieren ist, über eine benutzerfreundliche Oberfläche verfügt 
und die Möglichkeit bietet, die digitalisierten CDs unter Berücksichtigung der rechtlichen Rahmenbedingungen zu streamen.  

\section{Zur Dokumentation}  
Die Dokumentation gliedert sich in zwei Teile: Der erste Teil behandelt die technischen Hintergründe, 
während der zweite Teil die praktische Umsetzung in der Bibliothek beschreibt. 
Damit soll sie einerseits einen fundierten Einstieg in die Themenbereiche Netzwerk und Serveradministration bieten 
und andererseits als Anleitung zur Nutzung und Wartung des Medienservers dienen.  

Im ersten Teil werden grundlegende Begriffe erläutert, die Entwicklung von Servern und Medienservern nachgezeichnet 
sowie deren Anwendungsbereiche dargestellt. Darauf aufbauend werden technische Aspekte der Serverarchitektur, 
der Administration und der Netzwerktechnik vorgestellt, bevor auf spezifische Eigenschaften von Medienservern eingegangen wird. 
Abschließend wird die besondere Rolle von Medienservern im Bibliothekskontext betrachtet.  

Der zweite Teil beschreibt die praktische Umsetzung des Projekts. 
Dazu zählen die Definition der Zielsetzung, die Darstellung der Voraussetzungen hinsichtlich Hard- und Software sowie des Netzwerks, 
die detaillierte Installation und Konfiguration der benötigten Komponenten, 
die Integration in die bestehende IT-Infrastruktur sowie die Einrichtung der Benutzerverwaltung und Zugriffsrechte. 
Darüber hinaus werden Testverfahren und Strategien zur Fehlerbehebung dokumentiert.  

Den Abschluss der Arbeit bilden ein Fazit mit einer kritischen Reflexion des Projekts sowie ein Ausblick auf mögliche Weiterentwicklungen.

% ------ Theoretische Grundlagen ------
\chapter*{Theoretische Grundlagen}
\addcontentsline{toc}{chapter}{Theoretische Grundlagen}
\setcounter{section}{0}

\section{Einführung in Server und Medienserver}
Server bilden das Fundament moderner IT-Infrastrukturen.
Sie übernehmen zentrale Aufgaben bei der Bereitstellung von Diensten 
und der Verwaltung von Daten. 
Im Zusammenhang mit Medienservern steht vor allem die Speicherung, 
Organisation und Übertragung digitaler Inhalte wie Musik, 
Videos oder Bilder im Vordergrund. 

Medienserver ermöglichen es, solche Inhalte in Echtzeit zu streamen, 
ohne dass ein vollständiger Download notwendig ist. 
Ihre Entwicklung ist eng mit der allgemeinen Geschichte von Servertechnologien und Netzwerken verknüpft 
und reicht von klassischen Rechenzentren über den Aufstieg des Internets bis hin zu modernen Heim- und Cloudlösungen. 

Heute finden Medienserver Einsatz in unterschiedlichsten Bereichen - 
von der privaten Nutzung über Unternehmen bis hin zu Bibliotheken, 
die digitalisierte Bestände für ihre Nutzer zugänglich machen.

  \subsection{Begriffsdefinitionen}
  Als \emph{Server} bezeichnet man einen „Rechner, 
  der für andere in einem Netzwerk mit ihm verbundene Systeme bestimmte Aufgaben übernimmt 
  und von dem diese ganz oder teilweise abhängig sind“. \footcite{duden_server}

  In diesem Zusammenhang ist ein \emph{Netzwerk} ein Zusammenschluss von „zwei oder mehr Computern,
  die miteinander verbunden sind, um Daten elektronisch auszutauschen.“
  (Übersetzung nach \footcite{britannica_network})

  Ein \emph{Medienserver} ist eine spezialisierte Form eines Servers, 
  die darauf ausgelegt ist, digitale Medieninhalte wie Audio, Video oder Bilder zu speichern, 
  zu verwalten und über ein Netzwerk für Clients bereitzustellen.\footcite[Vgl.][S.~131 ~ff.]{steinmetz_multimedia}

  Unter \emph{Streaming} versteht man die Übertragung von Audio- bzw. Videodaten von einem Server auf einen Client, 
  wobei die Wiedergabe umgehend erfolgt.\footcite{gabler_streaming}
  Multimedia-Inhalten können so bereits während der Übertragung konsumiert werden, 
  ohne dass eine vollständige Speicherung der Daten auf dem Endgerät erforderlich ist.

  Server und Clients bilden damit die grundlegende Kommunikationsbasis in Netzwerken. 
  Medienserver stellen eine spezielle Ausprägung dar, 
  die insbesondere für die effiziente Bereitstellung von Streaming-Inhalten optimiert sind.

  \subsection{Historische Entwicklung}
  Die Entwicklung von Servern und Netzwerken ist eng mit der allgemeinen Geschichte der Computerkommunikation verknüpft. 
  Erste Formen von Rechnernetzen entstanden bereits Ende der 1950er Jahre mit dem \ac{ARPANET}, 
  das als Vorläufer des heutigen Internets gilt 
  und den Grundstein für die paketorientierte Datenübertragung legte.\footcite[Vgl.][S.~45~f.]{tanenbaum_computernetworks}

  In den frühen 1970er Jahren zeigte sich, dass die bestehenden Protokolle des \ac{ARPANET} nicht ausreichten, 
  um heterogene Netzwerke wie Funk- oder Satellitennetze zu integrieren. 
  Vor diesem Hintergrund entwickelten Vinton Cerf und Robert Kahn 1974 das \ac{TCP}, 
  das später in die heute gebräuchliche Protokollfamilie \ac{TCP}/\ac{IP} aufgeteilt wurde. 
  \ac{TCP}/\ac{IP} ermöglichte die zuverlässige Kommunikation über unterschiedliche Netzwerke hinweg 
  und bildete die Grundlage für die Interoperabilität moderner Netze.\footcite[Vgl.][S.~45]{tanenbaum_computernetworks}
  Im Jahr 1983 wurde \ac{TCP}/\ac{IP} im \ac{ARPANET} als verbindlicher Standard eingeführt,
  was gemeinhin als Geburtsstunde des modernen Internets gilt.\footnote{Vgl. \cite[S.~2]{postel_rfc801}; \cite{britannica_tcpip}.}

  In den 1980er und 1990er Jahren etablierte sich das Client-Server-Modell als dominierendes Paradigma für den Datenaustausch. 
  Hierbei übernehmen Server die Rolle zentraler Dienstleister, 
  während Clients auf deren Ressourcen zugreifen.\footcite[Vgl.][S.~114]{kurose_networking} 
  Mit der zunehmenden Verbreitung des Internets wurden Server in Unternehmen, 
  Hochschulen und öffentlichen Institutionen zu zentralen Infrastrukturen.

  Parallel dazu entwickelte sich der Bedarf an multimedialer Datenübertragung. 
  Erste Streaming-Verfahren wie RealAudio (1995) ermöglichten die kontinuierliche Übertragung von Audioinhalten, 
  ohne dass die Daten vollständig gespeichert werden mussten. 
  Diese Technologie wurde später auf Video übertragen 
  und in standardisierte Protokolle wie \ac{RTP} überführt.\footcite[Vgl.][S.~11~ff., S.~273~ff.]{steinmetz_multimedia}

  Seit den 2000er Jahren prägen Breitbandinternet und die Verbreitung mobiler Endgeräte die Nutzung multimedialer Inhalte. 
  Parallel dazu entwickelten sich adaptive Streaming-Technologien wie \ac{MPEG-DASH} (Standardisierung 2012)
  und Apple \ac{HLS} (2009), die eine effiziente und bandbreitenabhängige Übertragung von Audio- 
  und Videoinhalten ermöglichen.\footcite[Vgl.]{iso_mpegdash, apple_hls}
  Medienserver sind in diesem Kontext zu zentralen Plattformen für die Speicherung und Bereitstellung digitaler Bestände geworden 
  und finden heute sowohl im privaten Umfeld als auch in Institutionen wie Hochschulen und Bibliotheken Anwendung.

  \subsection{Anwenwendungsbereiche}
  Server übernehmen zentrale Aufgaben in der \ac{IT}, etwa als Datei-, Datenbank-, Web- oder E-Mail-Server. 
  Darüber hinaus kommen sie in Bereichen wie Virtualisierung, Cloud-Computing
  oder bei Sicherheitsdiensten (z.\,B. Authentifizierung, Firewalls) zum Einsatz.

  Medienserver bilden eine spezialisierte Kategorie: Sie speichern und verwalten
  digitale Audio-, Video- und Bildbestände und stellen diese über Netzwerke bereit.
  Einsatzfelder finden sich im privaten Umfeld (Streaming von Musik und Filmen),
  in Unternehmen (z.\,B. interne Schulungsvideos oder Marketingmaterial),
  im Bildungsbereich (Vorlesungsaufzeichnungen, E-Learning-Plattformen) sowie
  in Kulturinstitutionen wie Archiven und Bibliotheken, wo sie die Nutzung und
  Langzeitverfügbarkeit digitalisierter Sammlungen unterstützen.\footcite[Vgl.][S.~131~ff.]{steinmetz_multimedia}

\section{Grundlagen der Serverarchitektur}
Serverarchitekturen umfassen sowohl Hardware- als auch Softwareaspekte. 
Sie bilden die Grundlage für den Betrieb spezialisierter Systeme wie Medienserver, 
die neben klassischen Serverkomponenten auch spezielle Anforderungen an Speicher und Datenübertragung stellen.

  \subsection{Hardware- und Softwareaspekte}
  Ein Server besteht aus zentralen Hardwarekomponenten wie Prozessor, Hauptspeicher, Netzwerk- und Massenspeicherhardware. 
  Für den Dauerbetrieb sind Aspekte wie Zuverlässigkeit, Ausfallsicherheit, Energieeffizienz und Skalierbarkeit besonders wichtig. 
  Anders als bei Arbeitsplatzrechnern kommen häufig redundante Netzteile, unterbrechungsfreie Stromversorgungen, 
  spezielle Kühlungssysteme sowie redundante Netzwerkverbindungen zum Einsatz, 
  um eine kontinuierliche Verfügbarkeit zu gewährleisten.\footcite[Vgl.][S.~152541]{ahmed2021energy} 

  Auf der Softwareseite bilden Betriebssysteme die Grundlage für den Betrieb, 
  wobei sich stabile, sichere und gut wartbare Plattformen durchgesetzt haben. 
  Darüber hinaus sind Serverdienste (z.\,B. Web-, Datenbank- oder Streamingdienste) 
  sowie Middleware-Komponenten erforderlich, die den Zugriff von Clients ermöglichen 
  und die Kommunikation zwischen verschiedenen Anwendungen koordinieren. 
  Gerade bei Medienservern sind zudem Softwarelösungen zur effizienten Verwaltung, 
  Katalogisierung und Bereitstellung multimedialer Inhalte notwendig.

  \subsection{Betriebssysteme für Server}
  Zu den gängigsten Server-Betriebssystemen zählen insbesondere 
  Linux-Distributionen, Windows Server sowie \ac{UNIX}-Derivate.
  Linux gilt als besonders verbreitet im Bereich Web- und Medienserver, 
  da es durch Stabilität, Sicherheit und Flexibilität überzeugt und 
  vor allem als bevorzugte Plattform für Webserver wie Apache dient.\footcite[Vgl.][S.~963~ff.]{nemeth_unixlinux} 
  Windows Server findet häufig Anwendung in Unternehmensumgebungen, 
  insbesondere durch die Integration mit Active Directory, 
  das als zentrales Verzeichnis- und Authentifizierungssystem eine 
  wichtige Rolle spielt.\footcite[Vgl.][S.~1154~f.]{nemeth_unixlinux}

  \subsection{Virtualisierung und Containerisierung}
  Moderne Serverarchitekturen setzen zunehmend auf Virtualisierung und Containerisierung, 
  um Hardware effizienter auszunutzen und Dienste flexibel bereitzustellen. 

  Klassische Virtualisierungslösungen wie VMware oder \ac{KVM} ermöglichen die parallele Ausführung mehrerer 
  virtueller Maschinen auf einer physischen Hardware.\footcite[Vgl.][S.~1005, S.~995~f.]{nemeth_unixlinux} 

  Containerisierungstechnologien wie Docker und Kubernetes gehen darüber hinaus einen Schritt weiter, 
  indem sie Anwendungen in isolierten Umgebungen ausführen und dabei besonders ressourcenschonend sowie 
  skalierbar gestalten. Wie im Beitrag von Mao et al. (2020) hervorgehoben wird, 
  bildet „die container-basierte Virtualisierungstechnologie, 
  wie Docker und Kubernetes, die Grundlage für cloud-native Anwendungen“.\footcite{mao2020containers}

  \subsection{Dateisysteme und Speicherlösungen}
  Für Medienserver spielt die Wahl der Speicherarchitektur eine zentrale Rolle. 
  Netzwerkspeicherlösungen wie \ac{NAS} und \ac{SAN} 
  ermöglichen die zentrale Bereitstellung großer Datenmengen. 
  \ac{NAS}-Systeme stellen Speicher im Netzwerk auf Dateiebene bereit und zeichnen sich durch einfache Einrichtung, 
  schnellen Datenzugriff und unkomplizierte Administration aus.\footcite[Vgl.][S.~21857]{saravanamuthu2014study} 
  \ac{SAN}s hingegen arbeiten auf Blockebene und sind für besonders leistungsintensive Anwendungen optimiert; 
  sie bieten hohe Bandbreiten, niedrige Latenzen und ermöglichen die zentrale Verwaltung großer Speicherpools.\footcite[Vgl.][S.~21858~f.]{saravanamuthu2014study}  

  Moderne Speicherlösungen sind darüber hinaus auf niedrige Latenz, hohe Bandbreite und Skalierbarkeit ausgelegt. 
  In experimentellen Vergleichen konnte gezeigt werden, dass \ac{SAN}-Systeme bei großen Datenmengen und intensiven Workflows deutliche Leistungs- 
  und Latenzvorteile gegenüber \ac{NAS} haben.\footcite[Vgl.][Abschnitt~IV; Ergebnisse]{jaikar2016performance}  
  \ac{NAS}-Systeme dagegen bieten Dateizugriff über verbreitete Protokolle (z. B. \ac{NFS}, \ac{SMB}) 
  und sind häufig kostengünstiger in Anschaffung und Wartung.\footcite[Vgl.][S.~21857]{saravanamuthu2014study}

  Neben der Netzwerkanbindung ist Redundanz ein entscheidender Faktor: Mechanismen 
  wie \ac{RAID} schützen vor Datenverlust durch 
  Festplattenausfall, während Hot-Swapping und automatische Neusynchronisation 
  die Verfügbarkeit auch im Fehlerfall erhöhen. In der klassischen Untersuchung „\ac{RAID}: 
  High-Performance, Reliable Secondary Storage“ wird herausgearbeitet, dass \ac{RAID}-Systeme durch Striping über mehrere Festplatten 
  und durch Redundanz eine signifikante Verbesserung von Leistung und Zuverlässigkeit bieten, insbesondere bei großen Datenmengen 
  und paralleler Zugriffslast.\footcite[Vgl.][151 ~ff.]{chen2004raid}

\section{Serveradministration}
Die Administration eines Servers umfasst grundlegende Prozesse der Benutzerverwaltung, Wartung und Absicherung. 
Sie bildet die Voraussetzung für einen stabilen und sicheren Betrieb und ist in der Praxis oft ein kontinuierlicher Prozess. % \footcite[Vgl.][Kapitel~1.1]{nemeth_unixlinux}

  \subsection{Benutzer- und Rechteverwaltung}
  Ein zentrales Element der Serveradministration ist die Verwaltung von Benutzern und deren Zugriffsrechten. 
  In UNIX- und Linux-Systemen erfolgt die Identifikation über eindeutige Benutzerkennungen (\ac{UID}s) 
  und Gruppenzugehörigkeiten (\ac{GID}s).\footcite[Vgl.][S.~176~ff.]{nemeth_unixlinux}
  Das klassische UNIX-Berechtigungsmodell unterscheidet dabei drei grundlegende Kategorien: 
  \emph{user} (Besitzer), \emph{group} (Mitglieder der zugewiesenen Gruppe) und \emph{others} (alle übrigen Nutzer). 
  Für jede dieser Kategorien lassen sich Lese- (read, r), Schreib- (write, w) und Ausführungsrechte (execute, x) festlegen.\footcite[Vgl.]{wikipedia_dateisystemrechte}

  Zentral ist zudem die Trennung zwischen normalen Benutzerkonten und dem privilegierten \emph{Superuser} (\texttt{root}), 
  der uneingeschränkten Zugriff auf das gesamte System besitzt. 
  Viele moderne Distributionen nutzen anstelle direkter Root-Anmeldungen das \texttt{sudo}-Kommando, 
  das einzelnen Benutzern temporär administrative Rechte verleiht und gleichzeitig Aktionen protokolliert.\footcite[Vgl.][S.~112~ff.]{nemeth_unixlinux}

  Erweiterte Mechanismen wie \ac{ACL}s ermöglichen eine feinere Abstufung der Berechtigungen, 
  indem sie Zugriffsrechte für mehrere Benutzer und Gruppen individuell definieren.\footcite[Vgl.][S.~159~ff.]{nemeth_unixlinux} 
  In einigen Systemen wie Solaris findet darüber hinaus eine rollenbasierte Zugriffskontrolle (\ac{RBAC}) Anwendung. 
  Dieses Konzept weist Rechte nicht mehr einzelnen Benutzern, sondern Rollen zu, die wiederum von Benutzern übernommen werden können. 
  Dadurch lassen sich administrative Aufgaben gezielt delegieren, ohne umfassende Superuser-Rechte vergeben zu müssen.\footcite[Vgl.][S.~108]{nemeth_unixlinux}

  \subsection{Dienste und Prozesse}
  Die Funktionsfähigkeit eines Servers basiert wesentlich auf Prozessen und Diensten. 
  Während Prozesse allgemein laufende Programme im Betriebssystem darstellen, 
  sind Dienste spezielle Hintergrundprozesse, die in UNIX- und Linux-Systemen 
  traditionell als \emph{daemons} bezeichnet werden.\footcite[Vgl.]{wikipedia_daemon}  

  Die Verwaltung dieser Dienste erfolgt über das \emph{init}-System, 
  das beim Bootvorgang automatisch Prozesse startet und kontrolliert. 
  Dabei kommen distributionsspezifische Startskripte zum Einsatz.\footcite[Vgl.][S.~88~ff.]{nemeth_unixlinux}  

  In vielen modernen Linux-Distributionen hat sich \emph{systemd} etabliert, 
  das Dienste parallelisiert starten kann und erweiterte Funktionen wie Abhängigkeitsmanagement 
  sowie integriertes Logging bietet.\footcite[Vgl.]{wikipedia_systemd}   

  \subsection{Monitoring und Logging}
  Für den Betrieb von Servern ist die kontinuierliche Überwachung essenziell. 
  Monitoring umfasst sowohl die Ressourcennutzung (\ac{CPU}, \ac{RAM}, Festplatten, Netzwerk) als auch die Erreichbarkeit zentraler Dienste. 
  Hierfür stehen je nach System Werkzeuge wie \texttt{top} (Linux), \texttt{topas} (AIX) oder \texttt{prstat} (Solaris) zur Verfügung, 
  die eine regelmäßig aktualisierte Übersicht über aktive Prozesse und deren Ressourcennutzung bieten.\footcite[Vgl.][S.~133]{nemeth_unixlinux}
  Darüber hinaus ermöglichen sie Administratoren auch Eingriffe, 
  etwa durch das Senden von Signalen oder das Anpassen der Priorität von Prozessen.\footcite[Vgl.][S.~134]{nemeth_unixlinux}

  Logging erfolgt primär über das \emph{Syslog}-Framework, das Ereignisse zentral erfasst und in Logdateien strukturiert speichert.\footcite[Vgl.][S.~344~ff.]{nemeth_unixlinux}  
  Eine strukturierte Protokollauswertung ist entscheidend, um Fehlerquellen und sicherheitsrelevante Vorfälle nachvollziehen zu können. 
  Moderne Systeme ermöglichen zudem die Weiterleitung von Logs an zentrale Server oder die Integration in Analyseplattformen, 
  um eine konsolidierte Überwachung zu gewährleisten.\footcite[Vgl.][S.~348]{nemeth_unixlinux}

  \subsection{Backup- und Recovery-Strategien}
  Datenverluste durch Hardwareausfälle oder Benutzerfehler gehören zu den größten Risiken im Serverbetrieb. 
  Daher sind regelmäßige Backups sowie erprobte Wiederherstellungsstrategien unverzichtbar. 
  Gängige Verfahren sind \emph{inkrementelle} und \emph{differenzielle Backups}. 
  Bei inkrementellen Sicherungen werden jeweils nur die seit der letzten Sicherung 
  geänderten Daten gespeichert, während differenzielle Backups stets alle Änderungen 
  seit der letzten Vollsicherung erfassen.\footcite[Vgl.][S.~305~f.]{nemeth_unixlinux}  
  Diese Methoden reduzieren den Aufwand und Speicherbedarf gegenüber Vollsicherungen erheblich. 

  Für kritische Systeme werden zusätzlich \emph{Offsite-Backups} eingesetzt. 
  Das bedeutet, dass Kopien der Daten an einem geographisch getrennten Standort gespeichert werden, 
  sei es durch das Versenden physischer Medien oder durch Übertragung an entfernte Speicher/Cloud-Dienste. 
  Diese Maßnahme schützt vor lokalen Katastrophen wie Brand oder Naturereignissen 
  und ermöglicht eine schnelle Wiederaufnahme des Betriebs, wenn die Hauptanlage nicht nutzbar ist.\footcite[Vgl.]{wikipedia_offsite_data_protection}  

  \subsection{Sicherheitsaspekte}
  Die Absicherung von Servern erfordert ein mehrschichtiges Konzept, 
  das organisatorische, technische und prozessuale Maßnahmen umfasst.
  Ein ganzheitliches Sicherheitskonzept, das möglichst viele der folgenden grundlegenden Aspekte enthält ist unverzichtbar, 
  um Server vor Angriffen und Ausfällen zu schützen und die Verfügbarkeit kritischer Dienste sicherzustellen.
  \\
  \newline
  \textbf{Netzwerkschutz}:  
  Ein zentraler Bestandteil der Serversicherheit ist der Schutz der Netzwerkschnittstellen. 
  Hierzu werden Firewalls eingesetzt, um eingehenden und ausgehenden Datenverkehr anhand von Regeln zu kontrollieren. 
  Klassische Paketfilter analysieren Header-Informationen wie Quell- und Zieladresse oder Ports und können so unerwünschte Verbindungen blockieren.\footcite[Vgl.][S.~932~ff.]{nemeth_unixlinux}  
  \\
  \newline
  \textbf{Verschlüsselung}:  
  Um die Vertraulichkeit und Integrität der Kommunikation zu gewährleisten, werden Verschlüsselungstechniken eingesetzt. 
  \ac{TLS}/\ac{SSL} schützt Datenströme im Internet, \acp{VPN} verschlüsseln den gesamten Datenverkehr zwischen Standorten, 
  und \ac{SSH} ermöglicht eine abgesicherte Fernadministration.\footcite[Vgl.][S.~801, S.~971, S.~926~ff., S.~942]{nemeth_unixlinux}  
  \\
  \newline
  \textbf{Benutzer- und Rechteverwaltung}:  
  Ein konsequentes Berechtigungsmanagement stellt sicher, dass Benutzer nur Zugriff auf die Ressourcen haben, die sie tatsächlich benötigen. 
  Dazu gehören sichere Passwörter, Mechanismen wie \emph{Password Aging} (zeitliche Begrenzung der Passwortgültigkeit) 
  und die Vergabe von Rechten nach dem Prinzip des geringsten Privilegs. 
  So wird verhindert, dass kompromittierte Accounts zu weitreichenden Sicherheitsproblemen führen.\footcite[Vgl.][S.~905~ff.]{nemeth_unixlinux}  
  \\
  \newline
  \textbf{Systemhärtung}:  
  Viele Systeme sind in der Standardkonfiguration mit unnötigen Diensten ausgestattet, die zusätzliche Angriffsflächen bieten. 
  Systemhärtung bedeutet, diese Dienste konsequent zu deaktivieren und Konfigurationen sicherheitsorientiert vorzunehmen. 
  Damit sinkt die Wahrscheinlichkeit, dass Angreifer über Fehlkonfigurationen oder selten genutzte Software ins System eindringen können.\footcite[Vgl.][S.~902]{nemeth_unixlinux}
  \\  
  \newline
  \textbf{Updates und Patching}:  
  Die meisten erfolgreichen Angriffe erfolgen über bekannte, aber nicht geschlossene Schwachstellen. 
  Daher ist ein zeitnahes Einspielen von Patches für Betriebssystem und Anwendungssoftware unerlässlich. 
  Ein strukturierter Patch-Management-Prozess reduziert das Risiko signifikant.\footcite[Vgl.][S.~901]{nemeth_unixlinux}  
  \\
  \newline
  \textbf{Intrusion Detection und Monitoring}:  
  \acp{IDS} überwachen den Datenverkehr oder Host-Systeme auf verdächtige Aktivitäten. 
  \acp{IPS} gehen noch einen Schritt weiter und können erkannte Angriffe automatisch blockieren. 
  Beispiele sind Snort (Netzwerk-\ac{IDS}) oder OSSEC (Host-basiertes \ac{IDS}). 
  In Kombination mit einer kontinuierlichen Log-Analyse ermöglichen diese Werkzeuge eine frühzeitige Erkennung von Angriffen.\footcite[Vgl.][S.~918~ff.]{nemeth_unixlinux} 
  \\ 
  \newline
  \textbf{Backups und Recovery}:  
  Auch wenn alle präventiven Maßnahmen ergriffen werden, lassen sich Vorfälle nicht vollständig verhindern. 
  Regelmäßige Backups sind daher ein essenzielles Element der Sicherheit, da sie eine Wiederherstellung nach Angriffen oder Ausfällen ermöglichen. 
  Besonders im Kontext von Ransomware oder Datenmanipulation sind getestete Recovery-Strategien unverzichtbar.\footcite[Vgl.][S.~903]{nemeth_unixlinux} 
  \\ 
  \newline
  \textbf{Proaktives Sicherheitsmanagement}:  
  Technische Maßnahmen reichen allein nicht aus. 
  Ein umfassendes Sicherheitskonzept verlangt nach klar definierten Richtlinien, kontinuierlichen Audits und einem hohen Maß an Wachsamkeit. 
  Administratoren sollten regelmäßig die Wirksamkeit der Maßnahmen prüfen und neue Bedrohungslagen aktiv in die Planung einbeziehen. 
  So wird Sicherheit zu einem fortlaufenden Prozess und nicht zu einem einmaligen Projekt.\footcite[Vgl.][S.~901, S.~905]{nemeth_unixlinux}   

\section{Netzwerktechnik für Medienserver}
Netzwerke bilden die Grundlage für den Zugriff auf Medienserver. 
Dieser Abschnitt erläutert zentrale Konzepte, Protokolle sowie Leistungs- und Sicherheitsaspekte, 
die für den effizienten Betrieb relevant sind.  

  \subsection{Grundlagen der Netzwerktechnik}  
  Die Kommunikation in Netzwerken basiert auf dem \ac{TCP}/\ac{IP}-Protokollstapel. 
  \ac{IP} ist für die Adressierung und Weiterleitung von Paketen zuständig 
  und bildet die Grundlage für die Kommunikation in paketvermittelten Netzwerken.\footcite[Vgl.][S.~438]{tanenbaum_computernetworks}  
  Darüber hinaus sorgen \ac{TCP} und \ac{UDP} 
  auf der Transportschicht für den eigentlichen Datentransport. 
  \ac{TCP} stellt eine verbindungsorientierte, zuverlässige Übertragung mit Fehlerkorrektur und Flusskontrolle bereit, 
  während \ac{UDP} ein verbindungsloses, leichtgewichtiges Protokoll ist, 
  das insbesondere für zeitkritische Anwendungen wie Audio- und Videostreaming eingesetzt wird.\footcite[Vgl.][S.~228]{kurose_networking}
 
  Dienste werden über \emph{Ports} identifiziert, etwa Port~80 für \ac{HTTP} oder Port~443 für \ac{HTTPS}.\footcite[Vgl.][S.~554]{tanenbaum_computernetworks}  
  Für die Namensauflösung sorgt das \ac{DNS}, 
  das menschenlesbare Hostnamen in IP-Adressen übersetzt 
  und somit die Grundlage für jede netzwerkbasierte Medienübertragung bildet.\footcite[Vgl.][S.~611~f.]{tanenbaum_computernetworks}  

  \subsection{Streaming-Protokolle} 
  Zur Übertragung von Multimedia-Inhalten existieren verschiedene Protokolle. 
  Die wichtigesten werden im Folgenden vorgestellt.  
  \\
  \newline
  \textbf{HTTP:}
  \ac{HTTP} ist ein Anwendungsprotokoll auf der Anwendungsschicht und bildet das Herzstück des World Wide Web. 
  Es wird in einem Client- und einem Server-Programm implementiert, die über den Austausch von \ac{HTTP}-Nachrichten kommunizieren. 
  Diese Nachrichten sind nach einem standardisierten Format (RFC 1945, RFC 2616) definiert und regeln die Interaktion zwischen Webbrowser und Webserver.\footcite[Vgl.][S.~126]{kurose_networking} 
  \ac{HTTP} ist dabei ein \emph{zustandsloses} Protokoll, was bedeutet, dass der Server keine Informationen über vorherige Anfragen speichert. 
  Jede Anfrage wird unabhängig behandelt, wodurch \ac{HTTP} besonders einfach und skalierbar ist.\footcite[Vgl.][S.~128]{kurose_networking}   
  \\
  \newline
  \textbf{RTP:}  
  \ac{RTP} transportiert Audio- und Videodaten meist über \ac{UDP}. 
  Es ist speziell für Echtzeitanwendungen optimiert und unterstützt Mechanismen zur 
  Synchronisation verschiedener Medienstöme (z.\,B. Audio und Video) 
  sowie zur Kompensation von Jitter, der durch schwankende Paketlaufzeiten entsteht.\footcite[Vgl.][S.~546~ff.]{tanenbaum_computernetworks}   
  \\
  \newline
  \textbf{RTSP:}  
  \ac{RTSP} ist ein Steuerungsprotokoll, das Befehle wie \emph{Play}, \emph{Pause} oder \emph{Seek} ermöglicht. 
  Es wird häufig zusammen mit dem \ac{RTP} verwendet, 
  das die eigentliche Datenübertragung übernimmt.\footcite[Vgl.][S.~638~f.]{kurose_networking}  
  \\
  \newline
  \textbf{HLS:}
  \ac{HLS} ist ein von Apple entwickeltes Streaming-Protokoll, das in \emph{RFC 8216} standardisiert ist.
  Es basiert auf der Idee, Medieninhalte in kleine Segmente (Chunks) zu zerlegen, die sequenziell über \ac{HTTP} übertragen werden.
  Ein Manifest (Playlist) beschreibt die Abfolge dieser Segmente, wodurch auch unterschiedliche Qualitätsstufen bereitgestellt werden können.
  Dies ermöglicht \emph{adaptives Streaming}, bei dem der Client dynamisch zwischen verschiedenen Bitraten und Auflösungen wechseln kann,
  um Schwankungen in der Netzwerkbandbreite auszugleichen.\footcite[Vgl.][siehe HTTP Live Streaming Overview]{rfc8216}
  Dank der Nutzung von \ac{HTTP} ist \ac{HLS} besonders kompatibel mit bestehenden Infrastrukturen wie Caches und \acp{CDN}.\footcite[Vgl.][]{stockhammer2011dash}
  \\
  \newline
  \textbf{MPEG-DASH:}
  \ac{MPEG-DASH} ist ein von der MPEG-Gruppe entwickelter Standard für adaptives Multimedia-Streaming über \ac{HTTP}.
  Das Grundprinzip besteht darin, dass Multimedia-Inhalte in kleine Segmente zerlegt werden, die über herkömmliche \ac{HTTP}-Server bereitgestellt werden.
  Der Client entscheidet dynamisch, welche Segmente er anfordert, um sich an schwankende Netzwerkbedingungen und Geräteeigenschaften anzupassen.\footcite[Vgl.][S.~1~ f.]{stockhammer2011dash}
  Dadurch kombiniert \ac{MPEG-DASH} die weite Verbreitung von \ac{HTTP}-Infrastrukturen mit der Möglichkeit eines qualitativ stabilen Medienkonsums auch unter variablen Bandbreitenbedingungen.
    
  \subsection{Leistungsanforderungen}  
  Streaming-Anwendungen stellen hohe Anforderungen an die Netzwerkinfrastruktur. 
  Neben ausreichender \textbf{Bandbreite} ist vor allem geringe \textbf{Latenz} entscheidend, 
  insbesondere bei Live-Übertragungen oder interaktiven Anwendungen. 
  Eine wesentliche Rolle spielt außerdem die \textbf{Pufferung}, 
  die Jitter (Schwankungen in der Paketlaufzeit) ausgleichen soll. 
  Typische Verfahren sind Pre-Buffering und adaptive Puffergrößen.\footcite[Vgl.][S.~697~ff.]{tanenbaum_computernetworks}  

  \subsection{Qualität und Sicherheit}  
  Die Sicherstellung einer konstanten Übertragungsqualität erfordert \ac{QoS}-Mechanismen.  
  \ac{QoS} bezeichnet Techniken, die Netzwerkressourcen gezielt steuern, um die Anforderungen von Multimedia-Anwendungen zu erfüllen.\footcite[Vgl.][S.~9~ff.]{steinmetz_multimedia}  
  Im Folgenden werden einige gängige \ac{QoS}-Mechanismen vorgestellt: 
  \\
  \newline
  \textbf{Traffic Shaping:}  
  Verfahren wie \emph{Token Bucket} oder \emph{Leaky Bucket} regulieren die Burstartigkeit von Datenströmen, indem sie den Datenfluss glätten und Spitzenlasten abfangen.  
  Dadurch wird ein gleichmäßigerer Durchsatz erreicht, der insbesondere für kontinuierliche Audio- und Videoübertragungen wichtig ist.\footcite[Vgl.][S.~61~f.]{steinmetz_multimedia}  
  \\
  \newline
  \textbf{Rate Control und Scheduling:}  
  Kontrollmechanismen wie \emph{Fair Queueing}, \emph{Virtual Clock} oder \emph{Delay Earliest-Due-Date} sorgen dafür, 
  dass Bandbreiten fair aufgeteilt und Verzögerungen minimiert werden.  
  Zugleich helfen sie, Jitter auszugleichen und zeitkritische Datenströme zu priorisieren.\footcite[Vgl.][S.~62~f.]{steinmetz_multimedia}  
  \\
  \newline
  \textbf{Resource Reservation:}  
  Um Paketverluste und Verzögerungen zu vermeiden, können Bandbreiten, Puffer und andere Ressourcen im Voraus reserviert werden.  
  Dies kann pessimistisch (Worst-Case) oder optimistisch (Durchschnittswert) erfolgen und garantiert so Mindestqualitäten für Multimediadienste.\footcite[Vgl.][S.~52~f.]{steinmetz_multimedia}  
  \\
  \newline
  \textbf{Admission Control:}  
  Bevor eine neue Verbindung zugelassen wird, prüft das Netzwerk, ob genügend Ressourcen vorhanden sind.  
  Fehlen diese, wird die Anfrage abgelehnt, um eine Überlastung zu verhindern und die Qualität bestehender Verbindungen nicht zu beeinträchtigen.\footcite[Vgl.][S.~50~f.]{steinmetz_multimedia}  
  \\
  \newline
  \textbf{Error Control:}  
  Fehlererkennungs- und Fehlerkorrekturverfahren (z.\,B. \ac{FEC}) sind essenziell, 
  um trotz Paketverlusten eine akzeptable Qualität sicherzustellen.  
  Dabei können Redundanzdaten eingesetzt werden, die eine Rekonstruktion verlorener Informationen ermöglichen.\footcite[Vgl.][S.~68]{steinmetz_multimedia}  
  \\
  \newline  
  Aspekte der Sicherheit, die beim Betrieb eines Medienservers berücksichtigt werden müssen,
  wurden im Abschnitt „Serveradministration“ unter „Sicherheitsaspekte“ bereits beschrieben. 
    
\section{Spezifisches zu Medienservern}  
Medienserver unterscheiden sich von klassischen Servern vor allem durch ihre Spezialisierung auf die Verwaltung, Transkodierung und Auslieferung multimedialer Inhalte.  
Sie kombinieren Datenbanken, Streaming-Protokolle und Benutzerverwaltung und müssen dabei sowohl technische als auch rechtliche Anforderungen berücksichtigen.  
  
  \subsection{Typische Medienserver-Software}  
  Es existiert eine Vielzahl an Softwarelösungen, die sich im Funktionsumfang, in der Lizenzierung und in den Einsatzszenarien unterscheiden:  
  \\
  \newline 
  \textbf{Plex:}
  Plex zählt zu den bekanntesten Medienservern und wird vor allem im privaten Umfeld sowie in kleineren Organisationen genutzt, 
  um Audio-, Video- und Bilddateien zentral zu verwalten und auf verschiedensten Endgeräten bereitzustellen. 
  Typische Anwendungsfelder sind Heimnetzwerke, in denen Plex als Medienzentrale für Smart-TVs, Streaming-Boxen, Tablets und Smartphones dient. 
  Ein zentrales Merkmal ist die Echtzeit-Transkodierung, durch die Inhalte unabhängig von Format oder Endgerät konsumierbar werden. 
  Ergänzend bietet Plex mobile Clients, Webinterfaces und Zusatzfunktionen wie Offline-Synchronisation oder Live-TV, 
  die teilweise nur im kostenpflichtigen Abonnement „Plex Pass“ verfügbar sind.\footcite[Vgl.][Abschnitt „Plex Media Server“]{wikipedia_plex}\footcite[Vgl.][]{plex_docs}
  \\
  \newline
  \textbf{Emby:}
  Emby ist eine proprietäre Medienserver-Software, die Endgeräte wie Smart-TVs, Mobilgeräte und Webbrowser unterstützt. 
  In der Grundversion kostenlos nutzbar, erfordert der Zugriff auf erweiterte Funktionen wie mobile Synchronisation, 
  DVR oder Premium-Apps ein kostenpflichtiges Abonnement (\emph{Emby Premiere}). 
  Ursprünglich als Open-Source-Projekt gestartet, wechselte Emby später in eine proprietäre Lizenz. 
  Damit ist die Lösung für Privatanwender attraktiv, während sie im institutionellen Umfeld aufgrund der Kosten- 
  und Lizenzstruktur weniger flexibel erscheint.\footcite[Vgl.][]{wikipedia_emby}\footcite[Vgl.][]{emby_docs}
  \\
  \newline
  \textbf{Jellyfin:}
  Jellyfin ist eine vollständig freie und quelloffene Medienserver-Software, die als Community-getragene Alternative zu Plex und Emby entwickelt wird. 
  Sie eignet sich besonders für Szenarien, in denen Transparenz, Datenschutz 
  und Unabhängigkeit von kommerziellen Modellen eine Rolle spielen, wie etwa in Hochschulen oder öffentlichen Bibliotheken. 
  Jellyfin unterstützt die Verwaltung und das Streaming von Audio-, Video- und Bilddateien und bietet Clients für Webbrowser, Mobilgeräte und Smart-TVs. 
  Alle Funktionen, einschließlich Transkodierung und Multiuser-Verwaltung, 
  sind ohne Einschränkung verfügbar.\footcite[Vgl.][]{wikipedia_jellyfin}\footcite[Vgl.][]{jellyfin_docs}
  \\
  \newline
  \textbf{Navidrome:}
  Navidrome ist ein moderner, leichtgewichtiger Musikserver, der vollständig quelloffen entwickelt wird und vor allem für den Zugriff auf private Musiksammlungen konzipiert ist.
  Im Gegensatz zu umfassenden Multimedia-Lösungen wie Plex oder Emby konzentriert sich Navidrome ausschließlich auf Audioinhalte.
  Es unterstützt eine Vielzahl gängiger Audioformate (z. B. \ac{MP3}, \ac{FLAC}, \ac{AAC}) und bietet eine browserbasierte Benutzeroberfläche 
  sowie Clients für mobile Endgeräte über das Subsonic-\ac{API}.
  Navidrome zeichnet sich durch geringe Systemanforderungen, einfache Installation und eine aktive Community aus, 
  wodurch es auch auf ressourcenschwachen Servern oder in Bibliotheksumgebungen mit begrenzter Hardware problemlos betrieben werden kann.
  Ein weiterer Vorteil ist die konsequente Ausrichtung auf offene Standards 
  und Datenschutz: sämtliche Funktionen stehen ohne kostenpflichtige Zusatzmodule zur Verfügung.\footcite[Vgl.][]{navidrome2024}\footcite[Vgl.][]{wikipedia_navidrome}
  \\
  \newline  
  \textbf{VLC-Streaming:}
  Der \emph{VLC Media Player} ist eine weit verbreitete, freie und quelloffene Software der \emph{VideoLAN}-Organisation. 
  Neben der Wiedergabe nahezu aller gängigen Audio- und Videoformate umfasst VLC auch leistungsfähige Streaming-Funktionen. 
  Inhalte können beispielsweise über \ac{HTTP}, \ac{RTP} oder \ac{RTSP} verteilt werden, was den VLC für den Aufbau kleiner Streaming-Server, 
  Testumgebungen oder den schnellen Medientransfer prädestiniert. 
  Dank seiner Flexibilität und Plattformunabhängigkeit findet VLC Anwendung in Bildungseinrichtungen ebenso wie im privaten Bereich.\footcite[Vgl.][]{wikipedia_vlc}\footcite[Vgl.][]{vlc_docs}  
  \\
  \newline
  \textbf{Icecast:}
  \emph{Icecast}, entwickelt von der \emph{Xiph.org Foundation}, ist eine freie Open-Source-Software zur Einrichtung von Streaming-Servern. 
  Hauptsächlich im Audiobereich (z. B. Internetradios) eingesetzt, unterstützt Icecast auch Videostreams. 
  Neben offenen Formaten wie Ogg Vorbis, Opus und Theora können auch verbreitete Standards wie \ac{MP3} oder \ac{AAC} genutzt werden. 
  Durch seine Stabilität und Skalierbarkeit eignet sich Icecast besonders für Webradios, nichtkommerzielle Sender sowie für Bildungs- und Forschungseinrichtungen, 
  in denen offene Standards von zentraler Bedeutung sind.\footcite[Vgl.][]{wikipedia_icecast}\footcite[Vgl.][]{icecast_docs}  
  \\
  \newline
  \textbf{DLNA-basierte Systeme:}
  \ac{DLNA} ist ein Industriestandard, der die Interoperabilität zwischen Geräten im Heimnetzwerk sicherstellt. 
  \ac{DLNA}-konforme Server stellen Inhalte wie Musik, Videos und Bilder bereit, die von kompatiblen Clients 
  (Smart-TVs, Spielkonsolen, Streaming-Boxen oder mobilen Geräten) abgerufen werden können. 
  Typische Implementierungen sind \emph{MiniDLNA/ReadyMedia} oder in \ac{NAS}-Systeme integrierte Medienserver. 
  Während \ac{DLNA} im privaten Bereich nach wie vor verbreitet ist, verliert es im professionellen Umfeld zunehmend an Relevanz, da moderne, \ac{HTTP}-basierte Verfahren wie \ac{HLS} oder \ac{MPEG-DASH} flexiblere Möglichkeiten bieten.\footcite[Vgl.][]{wikipedia_dlna}\footcite[Vgl.][]{dlna_specs}

  \subsection{Datenformate und Standards}  
  Für den Betrieb eines Medienservers ist die Unterstützung gängiger Datenformate entscheidend, 
  da diese maßgeblich die Kompatibilität mit Endgeräten sowie die Qualität und Effizienz der Speicherung und Übertragung bestimmen.  
  \\
  \newline
  \textbf{Audioformate:}  
  Im Audiobereich haben sich unterschiedliche Standards etabliert, die sich hinsichtlich Qualität, Kompression und Einsatzgebiet unterscheiden.  
  Das \ac{MP3}-Format (\emph{MPEG-1/2 Audio Layer III}) ist verlustbehaftet komprimiert und gilt als de facto Standard im Musikbereich, 
  insbesondere wegen seiner geringen Dateigrößen und breiten Unterstützung durch Endgeräte.\footcite[Vgl.][S.~702~f.]{tanenbaum_computernetworks}  
  Für verlustfreie Archivierung wird häufig \ac{FLAC} (\emph{Free Lossless Audio Codec}) genutzt, 
  das bei identischer Klangqualität wie das Original eine deutliche Speicherreduktion ermöglicht.  
  \ac{AAC} (\emph{Advanced Audio Coding}), ebenfalls verlustbehaftet und von der MPEG-Gruppe spezifiziert, 
  wird heute von vielen Streamingdiensten und Plattformen (z.\,B. YouTube, iTunes, Spotify) als Standard eingesetzt.\footcite[Vgl.][]{openlearn_aac} 
  \ac{WAV} (\emph{Waveform Audio File Format}) speichert Audiodaten unkomprimiert, was höchste Qualität gewährleistet, jedoch mit hohem Speicherbedarf einhergeht.
  Dieses Format findet daher primär in professionellen Produktionsumgebungen oder für kurzfristige Verarbeitungsschritte Anwendung.\footcite[Vgl.][]{wikipedia_wav}  
  \\
  \newline
  \textbf{Containerformate:}  
  Neben reinen Audioformaten sind Containerformate für die Organisation komplexerer Inhalte entscheidend.  
  Das Matroska-Format (\ac{MKV}) ist ein freier, erweiterbarer Standard, der neben Audio- und Videoströmen auch Untertitel, 
  Kapitelinformationen und mehrere Tonspuren in einer Datei vereinen kann.\footcite[Vgl.][siehe 1. Introduction]{rfc9559}  
  \ac{MP4}, ein ISO-Standard auf Basis von \emph{MPEG-4 Part 14}, ist weltweit eines der am weitesten verbreiteten Containerformate 
  und bildet insbesondere die Grundlage für Video-Streaming über \ac{HTTP}. 
  Es überzeugt durch hohe Kompatibilität mit Abspielgeräten und Streaming-Plattformen.\footcite[Vgl.][S.~702~f.]{tanenbaum_computernetworks}
  \\
  \newline
  \textbf{Metadatenstandards:}
  Metadaten („Daten über Daten“) beschreiben Eigenschaften von Mediendateien und ermöglichen deren effiziente Suche, Auffindbarkeit und Verwaltung. 
  Ein weit verbreiteter Standard in \ac{MP3}-Dateien sind \ac{ID3}-Tags. 
  Diese Container erlauben das Einbetten von Informationen wie Titel, Interpret, Album, Genre oder Coverbilder direkt in die Datei.\footcite[Vgl.][siehe 4. Declared ID3v2 frames]{id3org_spec}

  Ein generischer, interdisziplinärer Standard ist Dublin Core. Dieser umfasst eine Menge von Kernfeldern (z. B. Title, Creator, Subject, Date, Format, Rights), 
  die zur Beschreibung digitaler Ressourcen genutzt werden können\footcite[Vgl.][siehe The Elements]{dublincore_set}. 
  Seine Stärke liegt in der Interoperabilität: Dublin Core wird von vielen Bibliotheks-, Museums- und Archivsystemen unterstützt.\footcite[Vgl.][siehe 1.1. What is Metadata?]{dublincore_using}

  Daneben gibt es weitere Metadatenstandards, die speziellere Anforderungen adressieren. 
  Beispiele sind \ac{METS} (Metadata Encoding and Transmission Standard), \ac{MODS} (Metadata Object Description Schema) 
  oder \ac{MARCXML}, die in Bibliotheks- und Archivumgebungen zusätzlich verwendet werden, 
  insbesondere wenn detailliertere bibliografische Informationen benötigt werden.\footcite[Vgl.][]{loc_mets} \footcite[Vgl.][]{loc_mods}  

  \subsection{Rechtsfragen}  
  Neben technischen Aspekten spielen rechtliche Rahmenbedingungen eine zentrale Rolle beim Betrieb von Medienservern.
  Im folgenden werden wesentliche Punkte skizziert, die insbesondere im Kontext von Bibliotheken und Bildungseinrichtungen relevant sind. 
  \\
  \newline
  \textbf{Lizenzen und Lizenzmodelle:}  
  Die Wahl der eingesetzten Software und Codecs ist auch aus lizenzrechtlicher Sicht relevant.  
  Freie Software wie Jellyfin unterliegt in der Regel der \ac{GPL}, die die Nutzung, Modifikation und Weitergabe des Quellcodes gestattet, 
  solange abgeleitete Werke unter denselben Bedingungen veröffentlicht werden.\footcite[Vgl.][]{gnu_gplv3}  
  Kommerzielle Systeme wie Plex oder Emby hingegen stehen unter proprietären Lizenzen, die Nutzung, Verbreitung und Anpassung einschränken.  
  Darüber hinaus können auch bei der Verwendung von Codecs Lizenzgebühren anfallen: So ist \ac{AAC} durch MPEG-LA patentiert 
  und unterliegt Lizenzkosten bei bestimmter kommerzieller Nutzung, ebenso H.264/\ac{AVC}.\footcite[Vgl.][]{wikipedia_mpegla}  
  \\
  \newline
  \textbf{Urheberrechtliche Rahmenbedingungen:}  
  Die Bereitstellung von Medieninhalten wird maßgeblich durch das \ac{UrhG} geregelt.  
  Nach §~53 \ac{UrhG} sind Privatkopien zwar grundsätzlich erlaubt, jedoch nur im engen persönlichen Umfeld.  
  Eine öffentliche Zugänglichmachung nach §~19a \ac{UrhG} – wie sie bei einem Medienserver innerhalb einer Organisation oder Bibliothek vorliegt –
  setzt hingegen entsprechende Nutzungsrechte oder Lizenzen der Rechteinhaber voraus.\footcite[Vgl.][§§~53, 19a UrhG]{urhg2025}  
  \\
  \newline
  \textbf{Bibliotheksrecht im Hochschulkontext:}  
  Für Hochschulbibliotheken gelten Sonderregelungen.  
  §~60a \ac{UrhG} erlaubt die Nutzung urheberrechtlich geschützter Werke für Unterricht und Lehre, etwa in Kursen oder in einer Lernplattform.  
  §~60e \ac{UrhG} regelt darüber hinaus Nutzungen durch Bibliotheken, beispielsweise die Bereitstellung von Werken in elektronischer Form für Forschungs- und Unterrichtszwecke.  
  Dennoch müssen in der Praxis bestehende Lizenzverträge und Verlagsbedingungen beachtet werden, 
  da gesetzliche Schrankenregelungen nicht alle Nutzungsformen abdecken.\footcite[Vgl.][§§~60a, 60e UrhG]{urhg2025}  

\section{Medienserver im Bibliothekskontext}  
Der Einsatz von Medienservern in Bibliotheken eröffnet neue Möglichkeiten für den Zugang zu digitalen Sammlungen, bringt aber auch besondere Anforderungen mit sich – technisch, rechtlich und hinsichtlich Langzeitverfügbarkeit.

  \subsection{Digitalisierung von Beständen}  
  Bibliotheken besitzen oft analoge oder hybride Bestände – etwa Audio- und Videomedien, Filmarchive oder Tonträger –, die durch Digitalisierung langfristig gesichert und zugänglich gemacht werden sollen. Der Prozess gliedert sich idealerweise in folgende Phasen:

  \begin{enumerate}
    \item \textbf{Auswahl und Priorisierung:}  
      Nicht alle Bestände können sofort digitalisiert werden. 
      Kriterien für eine sinnvolle Auswahl sind u. a. der Erhaltungszustand, die Nutzungshäufigkeit, die rechtliche Situation sowie historische oder kulturelle Bedeutung. Institutionelle Richtlinien oder internationale Leitlinien wie \ac{UNESCO}/\ac{PERSIST} geben dazu Orientierung.\footcite[Vgl.][]{unesco_persist_guidelines}  

    \item \textbf{Erfassung und Digitalisierung:}  
      Die Objekte werden mit geeigneten Geräten gescannt und digitalisiert (z. B. Scanner, Filmabtaster oder spezielle Audiogeräte). 
      Wichtig ist, dass die digitalen Dateien eine hohe Qualität (z. B. Auflösung, Farbtiefe, Samplingrate) aufweisen, 
      sodass sie als Masterversionen für spätere Ableitungen dienen können.  
      In der Bibliothek der \ac{HfM} Karlsruhe werden beispielsweise \ac{WAV}-Dateien in \ac{CD}-Qualität (44,1 kHz, 16 Bit) für Audio sowie JPEG-Scans mit 300 dpi für Booklets erstellt.  
      Für die Bereitstellung auf dem neuen Medienserver werden die Audiodateien in das verlustfreie \ac{FLAC}-Format transkodiert und die JPEG-Dateien zu \acp{PDF} zusammengefasst.  
      Weitere Details hierzu finden sich im Kapitel „Praktische Umsetzung“.  
    
    \item \textbf{Speicherung und Sicherung:}
      Die digitalen Dateien werden in einem strukturierten Dateisystem oder einer Datenbank abgelegt, 
      idealerweise mit einer klaren Ordnerstruktur und aussagekräftigen Dateinamen. 
      Parallel dazu sind regelmäßige Backups und Replikationen an verschiedenen Standorten essenziell, 
      um Datenverluste durch Hardwareausfälle, menschliche Fehler oder Katastrophen zu vermeiden.
  
    \item \textbf{Nachbearbeitung und Metadatenanreicherung:}  
      Nach der Erfassung werden die Rohdaten optimiert (z. B. Rauschfilter, Farbkorrektur) und in normative Formate überführt. 
      Parallel dazu werden Metadaten eingepflegt — technisch, beschreibend und strukturell —, um Auffindbarkeit, Verwaltung und Langzeitnutzung zu ermöglichen.
      Dieser Prozess wir im Rahmen dieser Arbeit verbessert werden, indem Metadaten bei der Konvertierung ins \ac{FLAC}-Format anhand der Datei-Benennung eingebettet werden.
      Mehr dazu ebenfalls im Kapitel „Praktische Umsetzung“.

    \item \textbf{Ableitung von Zugriffsvarianten:}  
      Für den täglichen Zugriff werden üblicherweise abgeleitete Versionen (z. B. mit kleinerer Auflösung oder effizienteren Codecs) erzeugt,
      während die Masterdateien sicher archiviert bleiben.
      Die Auflösung für das Streaming kann üblicherweise bei der zuvor vorgestellten Software für Medienserver eingestellt und dynamisch angepasst werden.
  \end{enumerate}  

  \subsection{Zugriff und Rechteverwaltung}  
  Im Bibliothekskontext bestehen oft restriktive Anforderungen an den Zugriff auf Medien:
  \\
  \newline
  \textbf{Eingeschränkter Zugang:} Der Zugang zu digitalisierten Medien erfolgt häufig nur innerhalb des Hochschulnetzes, 
  um urheberrechtliche Beschränkungen und Lizenzvereinbarungen zu wahren.  
  \\
  \newline
  \textbf{Authentifizierung und Autorisierung:} Bibliotheken nutzen bestehende Identity-Management-Systeme (z. B. Shibboleth, LDAP, OpenID Connect), 
  um sicherzustellen, dass nur berechtigte Nutzer (Studenten, Mitarbeitende) Zugriff haben.  
  \\
  \newline
  \textbf{Digitale Rechteverwaltung (\ac{DRM}) / Lizenzsteuerung:} In manchen Fällen sind Inhalte lizenzpflichtig und müssen mit \ac{DRM}-Technologien geschützt werden 
  oder der Zugriff auf bestimmte Zeitfenster begrenzt sein.  
  \\
  \newline
  \textbf{Auditierung und Protokollierung:} Jede Nutzung (z. B. Streamabruf, Download) sollte protokolliert werden, 
  um Vertragsbedingungen zu überwachen, Missbrauch zu erkennen und Nutzungsstatistiken zu führen.  

  \subsection{Nachhaltigkeit und Langzeitarchivierung}  
  Die Sicherung digitaler Medien über Jahrzehnte hinweg erfordert robuste Strategien:
  \\
  \newline
  \textbf{Redundanz und Verteilung (3-2-1 Regel):}  
  Mindestens drei Kopien, auf zwei unterschiedlichen Speichermedien und eine Kopie an einem externen Standort. 
  Die Regel reduziert das Risiko von Datenverlust erheblich, da sie nicht nur Hardwaredefekte abdeckt, sondern auch Gefahren wie Softwarefehler, versehentliches Löschen oder Schadsoftware (z.\,B. Ransomware).
  Durch die räumliche Trennung einer Kopie („offsite“) ist zudem gewährleistet, dass selbst Katastrophenfälle wie Brand, Überschwemmung oder Diebstahl nicht alle Daten gleichzeitig gefährden.\footcite[Vgl.][siehe Backupstrategien]{wikipedia_datensicherung}
  In Bibliotheks- und Archivkontexten wird diese Strategie häufig als Mindeststandard angesehen, da sie eine langfristige Verfügbarkeit und Integrität der Bestände sicherstellt.  
  \\
  \newline
  \textbf{Migration und Formatpflege:}  
  Dateiformate und Speichermedien verändern sich im Laufe der Zeit, wodurch die Gefahr entsteht, dass Daten in veralteten oder nicht mehr unterstützten Umgebungen unzugänglich werden.  
  Um die langfristige Nutzbarkeit zu gewährleisten, müssen Archivbestände daher regelmäßig überprüft und gegebenenfalls in aktuelle, verlustfreie Formate migriert werden.  
  Dieser Prozess umfasst sowohl die technische Konvertierung (z.\,B. von proprietären in offene Formate) als auch die Übertragung auf moderne Speichersysteme.  
  Die \emph{Library of Congress} weist in ihren Leitlinien ausdrücklich darauf hin, dass Formatmigration und Medienaktualisierung essenzielle Strategien der digitalen Langzeitarchivierung sind.\footcite[Vgl.][siehe Sustainability Factors]{loc_formats}  
  \\
  \newline
  \textbf{Integritätsprüfung und Fixity-Checks:}  
  Digitale Bestände können im Laufe der Zeit durch Speicherfehler, Hardwaredefekte oder Übertragungsprobleme unbemerkt beschädigt werden.  
  Um die Unversehrtheit der Daten zu gewährleisten, werden regelmäßig \emph{Fixity-Checks} durchgeführt.  
  Dabei werden Prüfsummen (z.\,B. \ac{MD5}, \ac{SHA-256}) berechnet und mit früher gespeicherten Werten verglichen, um bitweise Veränderungen zu erkennen.  
  Ein kontinuierliches Monitoring dieser Integrität ist eine zentrale Maßnahme der digitalen Langzeitarchivierung 
  und wird in internationalen Empfehlungen wie den Richtlinien der \ac{NDSA} ausdrücklich empfohlen.\footcite[Vgl.][siehe Levels of Digital Preservation V2.0 Matrix und Curatorial Guidance]{ndsa_fixity}
  \\
  \newline
  \textbf{Cloud- vs. On-Premises-Lösungen:}  
  Bibliotheken stehen bei der Bereitstellung von Medienservern vor der Wahl zwischen einer lokalen Infrastruktur (\emph{On-Premises}) und der Nutzung von Cloud-Diensten.  
  Cloud-Lösungen bieten Vorteile wie einfache Skalierbarkeit, hohe Redundanz und oftmals geringere Einstiegskosten, gehen jedoch mit Risiken wie eingeschränkter Datenhoheit, fortlaufenden Betriebskosten und einer Abhängigkeit vom jeweiligen Anbieter einher.\footcite[Vgl.][S.~1]{paletta2015cloud}  
  On-Premises-Installationen ermöglichen dagegen die vollständige Kontrolle über Hardware, Software und Daten, erfordern jedoch Investitionen in Infrastruktur, Fachpersonal und Wartung.  
  Die Entscheidung hängt daher maßgeblich von den institutionellen Rahmenbedingungen, rechtlichen Vorgaben und langfristigen Strategien ab.
  \\
  \newline
  \textbf{Netzwerk der Kooperationen:}  
  Bibliotheken und Gedächtnisinstitutionen schließen sich zunehmend zu Verbünden und Konsortien zusammen, 
  um die Herausforderungen der digitalen Langzeitarchivierung und digitalen Dienste gemeinsam zu bewältigen.  
  Ein Beispiel ist \emph{Goportis}, der Verbund der drei zentralen Fachbibliotheken in Deutschland 
  (Technische Informationsbibliothek, ZB MED - Informationszentrum Lebenswissenschaften und ZBW - Leibniz-Informationszentrum Wirtschaft). 
  Goportis koordiniert unter anderem Strategien zur digitalen Langzeitarchivierung, 
  bietet gemeinsame Infrastrukturen und setzt auf arbeitsteilige Services im Bereich Forschung und Datenmanagement.\footcite[Vgl.][]{wikipedia_goportis}  
  Ein weiteres Beispiel ist der \emph{Südwestdeutsche Bibliotheksverbund (\ac{SWB})}, dem zahlreiche wissenschaftliche Bibliotheken in Baden-Württemberg 
  und angrenzenden Regionen angehören. Unter anderem ist die Bibliothek der HfM hier Mitglied. 
  Der \ac{SWB} betreibt eine zentrale Datenbank für Metadaten und digitale Ressourcen und stellt seinen Mitgliedsbibliotheken Werkzeuge zur Verfügung, 
  um Ressourcen zu erschließen, zu archivieren und kooperativ zugänglich zu machen.\footcite[Vgl.][]{swb}  
  Solche Netzwerke bieten organisatorische Vorteile wie abgestimmte Policies, gemeinsame Workflows zur Metadatenpflege 
  und Format-Migration sowie eine geteilte Infrastruktur für Monitoring, Austausch und Weiterentwicklung.


% ------ Praktische Umsetzung ------
\chapter*{Praktische Umsetzung}
\addcontentsline{toc}{chapter}{Praktische Umsetzung}
\setcounter{section}{0}

\section{Zielsetzung}
Als bei mir die Idee aufkam, in der Bibliothek der \ac{HfM} Karlsruhe einen neuen Medienserver aufzubauen, war meine Vorstellung, eine moderne, flexible, benutzerfreundliche 
und nachhaltige Lösung selbst zu programmieren, die es ermöglicht, die digitalisierten CDs zugänglich zu machen.
Im Gespräch mit dem Bibliotheksleiter Marc Weisser erfuhr ich, dass der alte, inzwischen stillgelegte Medienserver damals als Masterarbeit von Frederik Schroff konzipiert und umgesetzt worden war.
Damit war klar: Einen komplett neuen Medienserver mit eigens programmierter Benutzeroberfläche 
und Datenbank zu entwickeln, wäre ein sehr umfangreiches Projekt, das den Rahmen einer Bachelorarbeit sprengen würde.
Daher informierte ich mich über bestehende, quelloffene Medienserver-Software, die meinen Anforderungen möglichst nahekommt, um eine praktikable Lösung zu finden. 
Im Folgenden soll dargestellt werden, welche Ziele ich mir im Hinblick auf Funktionalität, Benutzerfreundlichkeit, Wartbarkeit, Sicherheit und rechtliche Rahmenbedingungen gesetzt habe.
  
Am Ende wird im Fazit überprüft, inwieweit diese Ziele erreicht wurden, welche Herausforderungen aufgetreten sind 
und welche Verbesserungen oder Erweiterungen in Zukunft möglich wären.

  \subsection{Funktionalität}
  Primäre Anforderungen im Bereich der Funktionalität sind ein flüssiges Streaming der digitalisierten CDs sowie die Möglichkeit, die zugehörigen Booklets abrufen zu können.
  Beides soll über eine Weboberfläche erfolgen.  
  Darüber hinaus sind folgende Punkte wünschenswert:
  \begin{itemize}
    \item automatische Erkennung und Verwaltung von Metadaten (Komponist, Werk, Satz, Album),
    \item eine effiziente Such- und Filterfunktion (z.\,B. nach Komponist, Werk, Interpret oder Genre),
    \item Unterstützung von Playlisten,
    \item Mehrbenutzerfähigkeit mit individuellen Konten und Berechtigungen.
  \end{itemize}

  \subsection{Benutzerfreundlichkeit}
  Damit das Angebot des neuen Medienservers für Studierende und Lehrende möglichst attraktiv ist, muss die Weboberfläche einfach und intuitiv zu bedienen sein. 
  Der Aufbau, das Design und die grundlegende Funktionalität sollten sich daher an bekannten Plattformen wie beispielsweise Spotify orientieren.  

  Erweiterte Funktionen, wie das Anlegen eines personalisierten Benutzeraccounts zum Erstellen eigener Playlisten, 
  sollen über eine einfache Registrierung per E-Mail-Adresse und Passwort zugänglich sein.  
  Gleichzeitig sollte die Nutzung auch ohne individuelle Anmeldung möglich bleiben: Dafür kann ein allgemeiner Bibliotheks-Account bereitgestellt werden, 
  der von allen genutzt werden kann.  

  Der Zugriff auf den Server sollte in erster Linie von einem Rechner in der Bibliothek erfolgen (ähnlich wie beim Naxos-Rechner). 
  Optional kann der Zugang auch für alle Geräte ermöglicht werden, die mit dem lokalen Hochschulnetzwerk (per LAN) verbunden sind.  

  Weitere Anforderungen an die Benutzerfreundlichkeit sind:
  \begin{itemize}
    \item kurze Ladezeiten und zuverlässiges Streaming,
    \item eine klare und konsistente Navigationsstruktur,
    \item mehrsprachige Oberfläche (mindestens Deutsch und Englisch),
    \item eindeutige und verständliche Fehlermeldungen.
  \end{itemize}

  \subsection{Wartbarkeit}
  \subsection{Wartbarkeit}
  Damit der Medienserver langfristig zuverlässig betrieben werden kann, ist eine gute Wartbarkeit entscheidend. 
  Die Installation und Konfiguration der Server-Software sollte möglichst standardisiert erfolgen, um eine einfache Reproduzierbarkeit zu gewährleisten. 
  Der Einsatz von Containervirtualisierung (z.\,B. Docker) erleichtert dabei sowohl die Installation als auch spätere Updates.  

  Wartung umfasst zudem die regelmäßige Aktualisierung der Server-Software und der darunterliegenden Betriebssystemkomponenten, 
  sowie die Sicherstellung von Backups der Musikdaten und Konfigurationsdateien.  
  Eine klare Dokumentation der Systemarchitektur und der administrativen Abläufe ist erforderlich, 
  damit auch Personen ohne tiefgehende technische Vorkenntnisse die Verwaltung übernehmen können.  

  Folgende Anforderungen ergeben sich für die Wartbarkeit:
  \begin{itemize}
    \item Verwendung etablierter Open-Source-Software mit aktiver Community und regelmäßigen Updates,
    \item klare und nachvollziehbare Ordner- und Datenstruktur,
    \item automatisierte Backups der Musikdatenbank und Konfiguration,
    \item Möglichkeit zur einfachen Wiederherstellung nach einem Ausfall,
    \item ausführliche Dokumentation der Installation, Konfiguration und Benutzerverwaltung,
    \item modularer Aufbau, sodass Komponenten (z.\,B. Datenbank, Weboberfläche) getrennt aktualisiert oder ersetzt werden können.
  \end{itemize}

  \subsection{Sicherheit}  
  Der Zugriff auf den Server soll grundsätzlich nur innerhalb des Hochschulnetzwerks möglich sein, 
  wodurch ein unkontrollierter Zugriff von außen vermieden wird.  

  Die Authentifizierung erfolgt entweder über einen allgemeinen Bibliotheks-Account oder über persönliche Benutzerkonten. 
  Dabei sollten Passwörter sicher verschlüsselt gespeichert und Mindestanforderungen an die Passwortstärke durchgesetzt werden.  
  Darüber hinaus ist es notwendig, dass die Server-Software regelmäßig aktualisiert wird, um bekannte Sicherheitslücken zu schließen.  

  Wichtige Anforderungen an die Sicherheit sind:
  \begin{itemize}
    \item Zugriffsbeschränkung auf das Hochschulnetzwerk (z.\,B. IP-Filter oder VPN),
    \item sichere Speicherung von Zugangsdaten (Hashing und Salt),
    \item Rollenkonzepte für Benutzer (z.\,B. Admin, Standardnutzer, Gast),
    \item verschlüsselte Verbindungen per \ac{HTTPS},
    \item regelmäßige Updates der Server-Software und des Betriebssystems,
    \item Protokollierung von Anmeldeversuchen und relevanten Systemereignissen.
  \end{itemize}

  \subsection{Rechtliche Rahmenbedingungen}
  Beim Betrieb eines Medienservers in einer Hochschulbibliothek sind die rechtlichen Vorgaben, insbesondere des Urheberrechts, zu beachten. 
  Die Bereitstellung digitalisierter Tonträger ist in Deutschland durch das Urheberrechtsgesetz geregelt, 
  vor allem durch §~60e \ac{UrhG}, der spezielle Schrankenregelungen für Bibliotheken vorsieht.  
  Demnach dürfen Bibliotheken Werke aus ihrem Bestand in digitaler Form für Forschungs- und Unterrichtszwecke zugänglich machen, 
  sofern der Zugriff auf die Räumlichkeiten der Bibliothek oder das Hochschulnetzwerk beschränkt bleibt.  

  Eine öffentliche Zugänglichmachung außerhalb dieser Grenzen, beispielsweise über das offene Internet, ist hingegen nicht erlaubt.  
  Darüber hinaus dürfen die digitalisierten Werke ausschließlich für wissenschaftliche oder didaktische Zwecke genutzt werden, 
  eine kommerzielle Verwertung ist ausgeschlossen.  

  Folgende rechtliche Anforderungen ergeben sich daraus:
  \begin{itemize}
    \item Zugänglichmachung ausschließlich über das Bibliotheksnetzwerk,
    \item keine Verbreitung der digitalisierten Musikdateien an Dritte (Downloads nicht möglich),
    \item Einhaltung der Schrankenregelungen nach §~60e \ac{UrhG},
    \item Sicherstellung, dass die Nutzung ausschließlich zu Studien-, Lehr- und Forschungszwecken erfolgt.
  \end{itemize}

\section{Voraussetzungen}
  \subsection{Hardware}
  Für den Betrieb des Medienservers ist ein zuverlässiger Rechner erforderlich, der als zentrale Instanz für die Verwaltung und Bereitstellung der Musikdateien dient. 
  Ein handelsüblicher \ac{PC} mit einem \textbf{Intel i5 oder i7 Prozessor} (7.\,Generation oder neuer) bzw. einer vergleichbaren AMD-\ac{CPU}, mindestens 8\,GB \ac{RAM} und ausreichend Festplattenspeicher ist für den Anwendungsfall ausreichend. 
  Besonderes Augenmerk liegt auf der Speicherkapazität, da die Sammlung mehrerer tausend digitalisierter CDs schnell mehrere Terabyte umfassen kann. 
  Eine \ac{SSD} empfiehlt sich für das Betriebssystem und die Server-Software, während eine größere \ac{HDD} oder externe Laufwerke für die Musikdaten genutzt werden können.

  Die bisher für rund 4.200 CDs erstellten Masterfiles im \ac{WAV}-Format nehmen ca. 5\,TB Speicherplatz ein. 
  Im Bestand der Bibliothek befinden sich etwa 10.000 CDs – Tendenz steigend. 
  Auch wenn die Speicherung im \texttt{\ac{FLAC}}-Format deutlich weniger Speicherplatz beansprucht, 
  empfiehlt es sich, eine Festplatte mit mindestens 10\,TB Kapazität einzuplanen, um den zukünftigen Bedarf sicher abdecken zu können.

  \subsection{Software}
  Als Server-Software wird \textbf{Navidrome} eingesetzt, eine moderne, ressourcenschonende Open-Source-Lösung für Musik-Streaming. 
  Für die Bereitstellung und einfache Wartung wird Navidrome in einem \textbf{Docker-Container} betrieben. 
  Vorausgesetzt sind daher eine aktuelle Installation von Ubuntu (oder einem vergleichbaren Linux-basierten System). 
  Auf Client-Seite genügt ein Webbrowser, um auf die Musikbibliothek zuzugreifen. nginx

  \subsection{Netzwerk}
  Da die Audiodateien im \texttt{\ac{FLAC}}-Format vorliegen, muss das Netzwerk eine ausreichende Bandbreite für mehrere parallele Streams bereitstellen. 
  Ein einzelner \ac{FLAC}-Stream benötigt durchschnittlich etwa 1\,Mbit/s. 
  Für zehn gleichzeitige Streams ist somit eine Bandbreite von mindestens 15\,Mbit/s einzuplanen. 
  Dies liegt deutlich unterhalb der Kapazität eines \textbf{100\,Mbit/s-Netzwerks}, sodass dieses technisch ausreichen würde. 
  Empfohlen wird jedoch ein \textbf{Gigabit-LAN}, um ausreichend Reserven für gleichzeitige Dateioperationen und zukünftige Erweiterungen zu gewährleisten.

\section{Installation und Konfiguration}  
Die Installation und Konfiguration der zentralen Softwarekomponenten stellt die Grundlage für den zuverlässigen und sicheren Betrieb des Medienservers dar.
Nun werden die benötigten Werkzeuge und Dienste vorgestellt und ihre Einrichtung anhand einer praxisorientierten Schritt-für-Schritt-Anleitung beschrieben.
Damit soll der Aufbau des Medienservers in der Bibliothek nachvollziehbar und reproduzierbar gemacht werden.

  \subsection{Ubuntu Server}  
  Ubuntu Server ist eine weit verbreitete Linux-Distribution, die durch ihre Stabilität, breite Community-Unterstützung und regelmäßige Sicherheitsupdates überzeugt.  
  Das aktuelle Installations-ISO kann von der offiziellen Webseite heruntergeladen werden: \url{https://ubuntu.com/download/server}.  
  Nach dem Download wird das Image auf einen USB-Stick geschrieben (z.\,B. mit \texttt{Rufus} oder \texttt{dd} unter Linux).  
  Dabei ist zu beachten, dass der Stick keine wichtigen Daten enthält, da dieser vollständig überschrieben wird, und eine Mindestgröße von 5\,GB haben sollte.    
  Um die Installation zu starten, wird der Stick angeschlossen und über das Boot-Menü (Taste \texttt{F12}, \texttt{Esc} oder \texttt{Del}, abhängig vom Hersteller) ausgewählt.  
  Die textbasierte Installationsroutine führt anschließend durch Partitionierung, Netzwerkkonfiguration und die Einrichtung eines Administratorkontos. 
  Dabei können SSH und Docker bereits mitinstalliert werden. Der USB-Stick kann danach entfernt und der Server neu gestartet werden.
  Nähere Informationen zu diesem Vorgang sind in der offiziellen Dokumentation verfügbar: \url{https://ubuntu.com/server/docs/installation}.

  % --------------------------------------------------------------- 

  \subsection{SSH}  
  \emph{Secure Shell (SSH)} ist das zentrale Werkzeug für den sicheren Fernzugriff auf den Server.  
  Der SSH-Server kann unter Ubuntu bereits bei der Installation aktiviert werden. 
  Ist dies nicht der Fall, können nun folgende Schritte durchgeführt werden:  

  \begin{enumerate}
    \item Installation:
    
    \begin{minted}[breaklines, linenos]{bash}
# System aktualisieren
sudo apt update && sudo apt upgrade

# OpenSSH-Server installieren
sudo apt install openssh-server

# SSH-Dienst starten und aktivieren
sudo systemctl enable --now ssh

# Status überprüfen
sudo systemctl status ssh
    \end{minted}  

    \item Loggin:
    der Zugriff erfolgt dann von einem Client aus über:  
    
    \begin{minted}[breaklines, linenos]{bash}
# Zunächst IP-Adresse des Servers ermitteln (siehe unter enp0... inet z. B. 100.123.1.2)
ip a

# Dann Verbindung auf dem Client herstellen
ssh benutzername@server-ip

# Server mit exit verlassen
exit
    \end{minted}  

    \item SSH-Schlüssel statt Passwort nutzen:
    die offizielle Dokumentation befindet sich unter \url{https://www.openssh.com/}.  
    Für erhöhte Sicherheit wird empfohlen, die Passwort-Authentifizierung zu deaktivieren und stattdessen SSH-Schlüssel zu verwenden.
    Dafür sind folgende Schritte notwendig:
  
    \begin{minted}[breaklines, linenos]{bash}
# Auf dem Client SSH-Schlüssel generieren (falls noch nicht vorhanden)
ssh-keygen -t ed25519 -C "user@client"

# Loggin testen
ssh benutzername@server-ip

# Wenn das geklappte, kann der SSH-Dienst auf dem Server angepasst werden
sudo nano /etc/ssh/sshd_config
# Folgende Zeilen anpassen oder hinzufügen:
PasswordAuthentication no
PubkeyAuthentication yes
# Datei speichern und Editor verlassen (Strg+O, Enter, Strg+X)

# Nun den SSH-Dienst neu starten
sudo systemctl restart ssh
    \end{minted}

  \item Wichtige Befehle:
  für die Nutzung von SSH lohnt es sich folgende Befehle zu kennen:   
  \begin{minted}[breaklines, linenos]{bash}
# Service steuern
sudo systemctl start ssh
sudo systemctl stop ssh
sudo systemctl restart ssh
systemctl status ssh

# SSH-Schlüssel generieren und auf den Server kopieren (empfohlen)
ssh-keygen -t ed25519
ssh-copy-id benutzername@server-ip

# Datei von Client auf Server kopieren
scp /pfad/zur/datei benutzername@server-ip:/ziel/pfad/

# Datei vom Server auf Client kopieren
scp benutzername@server-ip:/pfad/auf/server/datei /lokaler/pfad/

# Verzeichnisse synchronisieren
rsync -av benutzername@server-ip:/remote/verzeichnis/ ./lokal/
  \end{minted}  
\end{enumerate}

% ---------------------------------------------------------------

  \subsection{Docker}  
  Docker ist eine Container-Plattform, die Anwendungen in isolierten Umgebungen ausführt. 
  Falls Docker nicht bei der Ubuntu-Installation mitinstalliert wurde, kann die Installation komfortabel über ein vorbereitetes Skript erfolgen. 
  Die offizielle Installationsanleitung ist verfügbar unter: \url{https://docs.docker.com/engine/install/}.  
  Dort findet sich auch der Inhalt des Skriptes \texttt{install-docker.sh}. Dieser sollte vor der Installation auf die neueste Version überprüft werden. 
  Ein Beispielskript (Stand 24. September 2025) findet sich im GitHub-Repository: \url{https://github.com/RathgebL/Bachelor_Thesis-New_Mediaserver}.
  Dieses enthält alle notwendigen Befehle zum Einrichten des Docker-Repositories und zur Installation der Docker-Pakete.
  Es kann nun wie folgt vorgegangen werden:  
  \begin{enumerate}
    \item Datenträger mit Skript verfügbar machen:
    \begin{minted}[breaklines, linenos]{bash}
# Stick anschließen und Gerät ermitteln (z.B. sdb1)
lsblk

# Output könnte z.B. so aussehen:
NAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS
sda      8:0    0 238.5G  0 disk
  sda1   8:1    0   512M  0 part /boot/efi
  sda2   8:2    0   238G  0 part /
sdb      8:16   1  14.9G  0 disk
  sdb1   8:17   1  14.9G  0 part

# Mountpoint erstellen (falls noch nicht vorhanden)
sudo mkdir -p /mnt/usb

# USB-Stick einhängen (Beispiel: sdb1)
sudo mount /dev/sdb1 /mnt/usb

# In das Verzeichnis des USB-Sticks wechseln
cd /mnt/usb
    \end{minted}

    \item Skript ausführbar machen und starten:
    \begin{minted}[breaklines, linenos]{bash}
chmod +x install-docker.sh
./install-docker.sh
    \end{minted}

    \item Überprüfen der Installation:
    \begin{minted}[breaklines, linenos]{bash}
# Verifiziere, dass der Docker-Dienst läuft
sudo systemctl status docker

# Testen der Installation mit dem Hello-World-Container
sudo docker run hello-world
    \end{minted}
  
    \item Nutzung:
    nach der Installation kann Docker Compose für die Verwaltung von Containern genutzt werden.  
    Dafür ist es sehr nützlich folgende Befehle, die im Verzeichnis ausgeführt werden, 
    in dem sich die \texttt{docker-compose.yml}-Datei befindet, zu kennen:

    \begin{minted}[breaklines, linenos]{bash}
# Container erstellen und im Hintergrund starten
sudo docker compose up -d

# Container starten und stoppen
sudo docker compose start
sudo docker compose stop

# Änderungen übernehmen (z.B. nach Anpassung der Compose-Datei)
sudo docker compose up -d --build

# Container-Status überprüfen
sudo docker compose ps
sudo docker ps

# Container beenden und entfernen
sudo docker compose down
    \end{minted}
  \end{enumerate}
 
% ---------------------------------------------------------------

  \subsection{Navidrome}
  \emph{Navidrome} ist ein leichtgewichtiger Musikserver, der über eine Weboberfläche sowie Subsonic-kompatible Clients genutzt werden kann. 
  Für den Einsatz als Medienserver in der Bibliothek der HfM Karlsruhe eignet sich Navidrome besonders gut, 
  da es ressourcenschonend, einfach zu administrieren und flexibel erweiterbar ist. 
  Durch die Nutzung als Docker-Container ist die Installation schnell durchführbar, Updates lassen sich unkompliziert einspielen, 
  und die Trennung von System und Anwendungsdaten ist klar gewährleistet.
  Im folgenden wird eine Schritt-für-Schritt-Anleitung geliefert, um Navidrome in einem Docker-Container zu installieren, zu konfigurieren und zu Nutzen.

  \begin{enumerate}
    \item Vorbereitungen:
    zunächst wird ein Arbeitsverzeichnis für den Container erstellt, in dem sich sowohl die Mediendateien als auch die Konfigurations- und Datenbankordner befinden:

    \begin{minted}[breaklines, linenos]{bash}
sudo mkdir -p /srv/navidrome
sudo mkdir -p /srv/navidrome/data
    \end{minted}

    Außerdem muss die Festplatte mit den Musikdateien (z.\,B. eine externe USB-Festplatte) eingebunden werden.
    
    \begin{minted}[breaklines, linenos]{bash}
# Platte anschließen und Gerät ermitteln (z.B. sdb1)
lsblk

# Output könnte z.B. so aussehen:
NAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS
sda      8:0    0 238.5G  0 disk
  sda1   8:1    0   512M  0 part /boot/efi
  sda2   8:2    0   238G  0 part /
sdb      8:16   1  14.9G  0 disk
  sdb1   8:17   1  14.9G  0 part

# Mountpoint erstellen (falls noch nicht vorhanden)
sudo mkdir -p /mnt/media
sudo mount /dev/sdb1 /mnt/media
      \end{minted}

    Im Anschluss wird eine \texttt{docker-compose.yml}-Datei mit den notwendigen Einstellungen angelegt. 
    Dazu muss folgender Befehl ausgeführt werden:

    \begin{minted}[breaklines, linenos]{bash}
cd /srv/navidrome
sudo nano docker-compose.yml
    \end{minted}

    Die Datei sollte folgenden Inhalt haben (Beispiel-Datei auch im GitHub-Repository verfügbar):
    
    \begin{minted}[breaklines, linenos]{yaml}
version: "3" # gegebenfalls anpassen oder weglassen
services:
  navidrome:
    image: deluan/navidrome:latest
    container_name: navidrome
    restart: unless-stopped # Container automatisch neustarten
    ports:
      - "4533:4533"
    environment:
      # nur das Nötigste als ENV
      ND_LOGLEVEL: "info"
      ND_SCANSCHEDULE: "1h"
      ND_ENABLEDOWNLOADS: "false" # erzwingt: keine Downloads
    volumes:
    # gegebenfalls anpassen
      - /home/navidrome/data:/data
      - /mnt/media/music:/music:ro
      - ./navidrome.toml:/navidrome.toml:ro
    \end{minted}

    \item Konfiguration:
    die Konfiguration von Navidrome erfolgt in der Datei \texttt{navidrome.toml} und auf der Weboberfläche.
    Der Inhalt der Datei sollte wie folgt sein (Beispielkonfigurationsdatei ist ebenfalls im GitHub-Repository verfügbar):
  
    \begin{minted}[breaklines, linenos]{toml}
# -----------------------------
# Pfade
# -----------------------------
MusicFolder = "/music"
DataFolder = "/data"

# -----------------------------
# Oberfläche
# -----------------------------
DefaultLanguage = "de"
EnableUserEditing = false             # Nutzer können ihre eigenen Daten nicht ändern
# EnableDownloads = false             # verhindert, dass Nutzer Musik-Dateien herunterladen
# UILoginBackground = "/data/bg.jpg"  # optional eigenes Hintergrundbild fürs Login
# UICustomCss = "/data/custom.css"    # eigenes CSS für UI-Anpassungen

# -----------------------------
# Streaming-Einstellungen
# -----------------------------
MaxUserSessions = 1                   # verhindert, dass ein Konto gleichzeitig mehrfach genutzt wird
TranscodingCacheSize = "500MB"        # Zwischenspeicher für Transkodierung
PreCacheTranscoding = true            # fängt schon an zu transkodieren, bevor der Nutzer Play drückt
ScannerParallelism = 4                # wie viele Threads der Scanner nutzt (abhängig von CPU)

# -----------------------------
# Sicherheit
# -----------------------------
LogLevel = "info"                     # mögliche Werte: debug, info, warn, error
EnableExternalServices = false        # verhindert, dass externe Dienste wie Last.fm/Spotify genutzt werden
BaseURL = "/navidrome"                # Basis-URL für Links

# -----------------------------
# Tags / Metadaten
# -----------------------------
[Tags]
# eigenes Feld für Booklet-URL
[Tags.BookletURL]
Aliases = ["bookleturl", "booklet_url"]
Type = "string"
Album = false
MaxLength = 512

# eigenes Feld für Dirigent
#[Tags.Conductor]
#Aliases = ["conductor", "dirigent"]
#Type = "string"
#Album = false

# -----------------------------
# Benutzer
# -----------------------------
SessionTimeout = 1800                 # nach wie vielen Sekunden Sessions auslaufen
PasswordStrength = "weak"             # simple Passwörter reichen aus
    \end{minted}

    Nähere Informationen zu den Konfigurationsmöglichkeiten sind in der offiziellen Dokumentation verfügbar: \url{https://www.navidrome.org/docs/configuration/}.
    
    Beim ersten Start wird man aufgefordert, ein Administrationskonto anzulegen.
    Über dieses Konto können weitere Nutzer angelegt und Rechte vergeben werden.

    \item Container starten:
    \begin{minted}[breaklines, linenos]{bash}
sudo docker-compose up -d

# Status prüfen
sudo docker-compose ps

# Start nach änderungen der Compose-Datei
sudo docker-compose up -d --build

# Weitere nützliche Befehle siehe Docker-Abschnitt
    \end{minted}

    \item Zugriff und Nutzung:
    Nach dem Start des Containers kann die Weboberfläche von Navidrome im Browser über die Adresse \url{http://<SERVER-IP>:4533} aufgerufen werden.   
    Navidrome durchsucht den angegeben Ordner für Musik automatisch nach passenden dateien.  
  
    Alle Benutzerdaten, Playlisten und Metainformationen werden im Ordner \texttt{/srv/navidrome/data} gespeichert 
    und bleiben somit auch nach einem Update des Containers  erhalten.

    \item Updates:
    Ein Update des Containers erfolgt in zwei Schritten:

    \begin{minted}[breaklines, linenos]{bash}
cd /srv/navidrome
sudo docker-compose pull
sudo docker-compose up -d
    \end{minted}

    Damit wird die aktuelle Version des Navidrome-Images heruntergeladen und der Container neu gestartet.
  \end{enumerate}

% ---------------------------------------------------------------

  \subsection{nginx}  
  \emph{nginx} ist ein moderner Webserver und Reverse Proxy, der sich durch hohe Performance auszeichnet.  
  Die offizielle Website bietet Installationshinweise und Downloads: \url{https://nginx.org/en/download.html}.  
  Folgende Schritte sind nun auf Ubuntu notwendig, um von der Installation bis zur Nutzung zu gelangen:

  \begin{enumerate}
    \item Installation:
    \begin{minted}[breaklines, linenos]{bash}
# Paketliste aktualisieren
sudo apt update

# nginx installieren
sudo apt install nginx -y

# nginx starten und beim Systemstart aktivieren
sudo systemctl enable --now nginx

# Status überprüfen
sudo systemctl status nginx

# Test im Browser oder mit curl (sollte "Welcome to nginx!" zurückgeben)
curl http://localhost
    \end{minted} 

    \item Konfiguration:
    die Konfiguration erfolgt über Dateien im Verzeichnis \texttt{/etc/nginx/sites-available/}, 
    die durch Symlinks nach \texttt{/etc/nginx/sites-enabled/} aktiviert werden.  
    Für den Medienserver empfiehlt sich eine Konfiguration wie im folgenden Beispiel (als txt-Datei auch im     GitHub-Repository verfügbar):  

    \begin{minted}[breaklines, linenos]{nginx}
server {
    listen 80;
    server_name mediaserver.local;

    # Booklets bereitstellen
    location /booklets/ {
        alias /mnt/media/booklets/;
        autoindex off;              # kein Verzeichnislisting
        autoindex_exact_size off;
        autoindex_localtime on;
    }

    # Weiterleitung an Navidrome
    location / {
        proxy_pass         http://127.0.0.1:4533;
        proxy_http_version 1.1;
        proxy_set_header   Upgrade $http_upgrade;
        proxy_set_header   Connection "upgrade";
        proxy_set_header   Host $host;
        proxy_set_header   X-Real-IP $remote_addr;
        proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header   X-Forwarded-Proto $scheme;
        proxy_redirect     off;
    }
}
    \end{minted}  

    \item Aktivierung:
    die Datei wird in \texttt{/etc/nginx/sites-available/mediaserver} abgelegt 
    und über einen Symlink aktiviert:  
    \begin{minted}[breaklines, linenos]{bash}
sudo ln -s /etc/nginx/sites-available/mediaserver \
           /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl reload nginx
    \end{minted}  

    \item Nutzung:
    Nach erfolgreicher Installation und Konfiguration, sind folgen Befehle nützlich zur Verwaltung von nginx:
    \begin{minted}[breaklines, linenos]{bash}
# Service steuern
sudo nginx -t                  # Konfiguration testen
sudo systemctl start nginx     # starten
sudo systemctl stop nginx      # stoppen
sudo systemctl restart nginx   # neu starten
sudo systemctl reload nginx    # nur Konfiguration neu laden

# Status prüfen
systemctl status nginx

# Logs einsehen
tail -f /var/log/nginx/access.log
tail -f /var/log/nginx/error.log
    \end{minted}
  \end{enumerate}

% ---------------------------------------------------------------

  \subsection{UFW}
  Zu guter letzt brauchen wir noch eine Firewall. 
  Die \emph{Uncomplicated Firewall} (UFW) ist eine benutzerfreundliche Schnittstelle und damit optimal für dieses Projekt. 
  Durch ihre einfache Syntax ermöglicht sie eine unkomplizierte und zugleich sichere Verwaltung von Netzwerkzugriffen. 
  Folgende Ports werden für den Betrieb des Medienservers benötigt:
   
  \begin{itemize}
    \item \textbf{SSH (22/tcp)} für die sichere Fernwartung,
    \item \textbf{4533/tcp} für Navidrome,
    \item \textbf{HTTP (80/tcp)} für den Webzugriff,
    \item \textbf{mDNS (5353/udp)} für die automatische Erkennung im lokalen Netzwerk.
  \end{itemize}

  Alle anderen eingehenden Verbindungen sollen standardmäßig blockiert werden. 
  Dadurch ist der Server vor ungewollten Zugriffen geschützt, ohne die für den Betrieb notwendigen Dienste einzuschränken. 
  Nun folgt die Installation und Grundkonfiguration von UFW in wenigen Schritten:

  \begin{enumerate}
    \item Installation:
    \begin{minted}[breaklines, linenos]{bash}
sudo apt update
sudo apt install ufw
sudo ufw enable
    \end{minted}

    \item Konfiguration:
    \begin{minted}[breaklines, linenos]{bash}
# Standardregeln setzen
sudo ufw default deny incoming
sudo ufw default allow outgoing

# Benötigte Ports freigeben
sudo ufw allow 22/tcp
sudo ufw allow 4533/tcp
sudo ufw allow 80/tcp
sudo ufw allow 5353/udp

# Firewall aktivieren
sudo ufw enable

# Aktuellen Status prüfen
sudo ufw status verbose
    \end{minted}

    \item Nutzung:
    nun werden noch alle wichtigen Befle zur Nutzung von UFW vorgestellt:
    \begin{minted}[breaklines, linenos]{bash}
  # Status prüfen
sudo ufw status
sudo ufw status verbose     # mehr Details
sudo ufw status numbered    # zeigt Regeln mit Nummern (praktisch zum Löschen)

# Firewall aktivieren/deaktivieren
sudo ufw enable             # Firewall einschalten
sudo ufw disable            # Firewall ausschalten

# Standardregeln setzen
sudo ufw default deny incoming    # alle eingehenden Verbindungen blockieren
sudo ufw default allow outgoing   # alle ausgehenden Verbindungen erlauben

# Regeln hinzufügen:
sudo ufw allow ssh                # SSH (Port 22)
sudo ufw allow 443/tcp            # HTTPS
sudo ufw allow from 192.168.1.0/24  # nur lokales Netz
sudo ufw allow 5353/udp           # Avahi/Multicast (.local)

# Regeln blockieren:
sudo ufw deny 23/tcp              # blockiert Telnet (Beispiel)
sudo ufw reject 23/tcp            # blockiert + sendet Ablehnung

# Regeln löschen:
sudo ufw delete allow 4533/tcp    # löschen über Befehl
sudo ufw status numbered          # Regeln nummeriert anzeigen
sudo ufw delete <number>          # löschen über Regelnummer

# Logging verwalten (Login-Detei unter /var/log/ufw.log):
sudo ufw logging on               # Logging aktivieren
sudo ufw logging off              # Logging deaktivieren
sudo ufw logging medium           # mehr Details
sudo ufw logging high             # sehr detailliert
sudo ufw reset                    # Achtung: setzt UFW komplett zurück und entfernt alle Regeln.
    \end{minted}
  \end{enumerate}

  Nach der Aktivierung sind die definierten Regeln sofort wirksam und bleiben auch nach einem Neustart des Servers erhalten.

% ---------------------------------------------------------------

\section{Integration in die bestehende IT-Infrastruktur}
  \subsection{Netzwerk-Anbindung}  
  \subsection{Datenbank anbinden}
    \subsubsection{Datenstruktur}
    Benennungskonvention
  \subsubsection{Dateiformate}
  \subsubsection{Metadaten}
    \begin{itemize}
      \item ID3-Tags
      \item Vorbis Comments
      \item FLAC-Metadaten
      \item MusicBrainz
    \end{itemize}
  \subsubsection{Datenverwaltung}
    Datenpflege
    Backup-Strategie
  \subsubsection{Datenquelle}
    Skript zur Digitalisierung
    Skript zur Metadatenanreicherung
    Externe Quellen
  \subsubsection{Datenimport}
\section{Benutzerverwaltung und Zugriffsrechte}
  \subsection{Nutzergruppen definieren}
\section{Testen und Fehlerbehebung}
  \subsection{Funktionstests}
  \subsection{Problemlösung}
    \subsubsection*{Probleme mit Navidrome}
    \begin{enumerate}
      \item Container läuft nicht:
      Bei "Error 502 Bad Gateway", sollte zunächst geprüft werden, ob der Docker-Container vorhanden ist und richtig läuft.

      \begin{minted}[breaklines, linenos]{bash}
# Status des Containers prüfen
sudo docker ps

# Der Output sollte in etwa so aussehen:
CONTAINER ID   IMAGE                     COMMAND                  CREATED          STATUS          PORTS                    NAMES
abcd1234efgh   deluan/navidrome:latest   "/entrypoint.sh /bin/…"   10 minutes ago   Up 10 minutes   0.0.0:4533->4533/tcp   navidrome
      \end{minted} 

      Falls der Container nicht läuft (kein Eintrag vorhanden), kann dieser mit folgendem Befehl gestartet werden:
      \begin{minted}[breaklines, linenos]{bash}
sudo docker-compose up -d
      \end{minted}

      \item Daten nicht erreichbar:
      Falls der Server zwar antwortet, aber die Inhalte nicht erreichbar sind (z.\,B. CDs werden ausgegraut dargestellt), 
      sollte überprüft werden, ob die Pfade in der \texttt{docker-compose.yml} korrekt sind.  
      In unserem Beispiel wird der Ordner \texttt{/mnt/media/music} in den Container eingebunden.  
      Sollte ein anderer Pfad genutzt werden, muss dieser entsprechend angepasst werden.
      Dafür folgenden Code ausführen:

      \begin{minted}[breaklines, linenos]{bash}
# Inhalt der docker-compose.yml anzeigen
sudo nano /srv/navidrome/docker-compose.yml # gegebenfalls Pfad zur yml-Datei anpassen
      \end{minted}

      Nach jeder Anpassung der \texttt{docker-compose.yml} muss der Container neu gestartet werden.  
      Andernfalls verwendet Navidrome weiterhin die alte Konfiguration.
      
      \begin{minted}[breaklines, linenos]{bash}
# Container neu starten
sudo docker-compose up -d --build
      \end{minted}

      \item Admin-Passwort vergessen:  
      Falls das Passwort für das Admin-Konto vergessen wurde, kann dieses zurückgesetzt werden, indem ein temporärer Container mit einer Umgebungsvariable gestartet wird.  
      Dies geschiet mit folgendem Code (das normale Setup über \texttt{docker-compose} bleibt unverändert):

      \begin{minted}[breaklines, linenos]{bash}
# Temporären Navidrome-Container starten und neues Passwort setzen. Gegebenenfalls Pfade und Port anpassen.
docker run --rm \
  -e ND_ADMIN_PASSWORD=Passwort \
  -v /srv/navidrome/data:/data \
  -v /mnt/expansion/music:/music:ro \
  -p 4533:4533 \
  deluan/navidrome:latest
      \end{minted}

      Danach im Webinterface mit Benutzer \texttt{admin} und mit "Passwort" einloggen. Nun ist es besonders wichtig in den Einstellungen ein neues sicheres Passwort festlegen.  
      Sobald dies geschehen ist, den temporären Container mit \texttt{CTRL+C} beenden und das System wie gewohnt neu starten.
    \end{enumerate}

    \subsubsection*{Probleme mit nginx}
    Wenn es zu Problemen beim Aufruf des Servers kommt, sollte zunächst geprüft werden, ob der nginx-Dienst richtig läuft.
    Beim aufbau des Medienservers sind folgende Probleme aufgetreten:
    
    \begin{enumerate}
      \item Berechtigungen:
      Falls Nginx beim Zugriff auf Dateien mit \texttt{403 Forbidden} antwortet, liegt dies meist an fehlenden Berechtigungen für den Prozessbenutzer \texttt{www-data}.  
      Dieser benötigt Lesezugriff auf die Dateien und Ausführungsrechte auf allen übergeordneten Verzeichnissen.

      \begin{minted}[breaklines, linenos]{bash}
# Test: kann www-data den Ordner sehen?
sudo -u www-data ls /mnt/media/booklets
      \end{minted}

      Falls dabei \texttt{Permission denied} ausgegeben wird, müssen die Rechte angepasst werden:

      \begin{minted}[breaklines, linenos]{bash}
# Ausführungsrechte für /mnt und /mnt/media hinzufügen
sudo chmod o+x /mnt /mnt/media

# Leserechte auf alle Dateien im Booklet-Ordner setzen
sudo chmod -R o+r /mnt/media/booklets
      \end{minted}

      \item Daten nicht erreichbar:
      Falls der Server zwar antwortet, aber die Inhalte nicht erreichbar sind (z.\,B. \texttt{404 Not Found}), 
      sollte überprüft werden, ob die Pfade in der nginx-Konfiguration korrekt sind.  
      Dabei ist besonders auf den Unterschied zwischen \texttt{alias} und \texttt{root} zu achten.  
      \texttt{alias} ersetzt den kompletten Pfad, während \texttt{root} den angegebenen Pfad an den URI anhängt.  
      In unserem Beispiel wird \texttt{alias} verwendet, da der URI \texttt{/booklets/} direkt auf den Ordner \texttt{/mnt/media/booklets/}
      abgebildet werden soll. Sollte ein anderer Pfad genutzt werden, muss dieser entsprechend angepasst werden.
      Nach jeder Anpassung einer nginx-Konfigurationsdatei muss überprüft und anschließend ein Reload durchgeführt werden.  
      Andernfalls verwendet nginx weiterhin die alte Konfiguration.

      \begin{minted}[breaklines, linenos]{bash}
# Syntax der Konfiguration prüfen
sudo nginx -t

# Konfiguration neu laden (ohne Dienstunterbrechung)
sudo systemctl reload nginx
      \end{minted}

      Erst danach sind die Änderungen aktiv.

      \item Hostname nicht auflösbar:
      Bei der Konfiguration des Reverse Proxys mit Nginx kann es vorkommen, dass der Server zwar über die IP-Adresse erreichbar ist, 
      nicht jedoch über den gewünschten Hostnamen (\texttt{mediaserver.local}).  
      Dieses Verhalten liegt nicht an Nginx, sondern an der Namensauflösung: Der Client kennt die Adresse für \texttt{mediaserver.local} nicht.  
      Es gibt zwei mögliche Lösungswege.
      \\
      \newline
      \texttt{Variante 1: Eintrag in der \texttt{/etc/hosts}-Datei des Clients}
      Durch einen manuellen Eintrag in die \texttt{/etc/hosts}-Datei des Clients (z.\,B. macOS) wird der Hostname einer festen IP-Adresse zugeordnet.  
      Dazu wird die Datei mit Root-Rechten geöffnet:

      \begin{minted}[breaklines, linenos]{bash}
sudo nano /etc/hosts
      \end{minted}

      Am Ende der Datei wird folgender Eintrag ergänzt (IP-Adresse anpassen):

      \begin{minted}[breaklines, linenos]{bash}
100.123.42.40   mediaserver.local # IP-Adresse des Servers anpassen
      \end{minted}

      Nach dem Speichern und Schließen der Datei kann der Name per \texttt{ping} überprüft werden:

      \begin{minted}[breaklines, linenos]{bash}
ping mediaserver.local # ctrl+c zum Abbrechen
      \end{minted}

      Erfolgt eine Antwort, ist der Server nun auch unter \texttt{http://mediaserver.local} im Browser erreichbar.  
      Diese Methode gilt allerdings nur für den jeweiligen Client und muss auf allen Endgeräten einzeln wiederholt werden.
      \\
      \newline
      \texttt{Variante 2: Multicast-DNS (mDNS) mit Avahi auf dem Server}
      Eine elegantere Lösung für lokale Netzwerke ist die Nutzung von Multicast-DNS (mDNS).  
      Dadurch kündigt der Server seinen Hostnamen automatisch im Netzwerk an, sodass alle Clients diesen ohne manuelle Anpassungen auflösen können.

      Dazu wird auf dem Server das Paket \texttt{avahi-daemon} installiert:

      \begin{minted}[breaklines, linenos]{bash}
sudo apt install avahi-daemon -y
sudo systemctl enable avahi-daemon
sudo systemctl start avahi-daemon
      \end{minted}

      Anschließend kann der Hostname (z.\,B. \texttt{mediaserver.local}) direkt im Browser oder per \texttt{ping} genutzt werden:

      \begin{minted}[breaklines, linenos]{bash}
ping mediaserver.local
      \end{minted}

      Vorteil dieser Methode ist, dass alle Geräte im lokalen Netzwerk sofort Zugriff erhalten, ohne dass die \texttt{/etc/hosts}-Datei auf jedem Client angepasst werden muss.
  \end{enumerate}
   
% ------ Fazit ------
\chapter*{Fazit}
\addcontentsline{toc}{chapter}{Fazit}
\setcounter{section}{0}
% Fazit folgt ...

\section{Ausblick}
% Ausblick folgt ...}


\cleardoublepage
\chapter*{Literaturverzeichnis}
\addcontentsline{toc}{chapter}{Literaturverzeichnis}
\printbibliography[heading=none]

\end{document}
