\documentclass[12pt,a4paper]{report}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[german]{babel}
\usepackage{minted}
\usepackage{csquotes}
\usepackage{graphicx}
\usepackage[colorlinks=true, linkcolor=blue, urlcolor=cyan]{hyperref}
\usepackage[backend=biber,style=authoryear]{biblatex}

\addbibresource{bibliography.bib}

\begin{document}

% ------ Titelblatt ------
\begin{titlepage}
    \centering
    {\Large Hochschule für Musik Karlsruhe \\[1em]}
    {\large Institut für Musikinformatik und Musikwissenschaft \\[6em]}

    {\Large \textbf{Bachelorarbeit} \\[2em]}

    {\LARGE \textbf{Neuer Medienservers für die Bibliothek der Hochschule für Musik Karlsruhe} \\[6em]}

    \begin{minipage}{0.9\textwidth}
        \raggedright
        \textbf{Autor:} Lennart Rathgeb \\
        \textbf{Matrikelnummer:} 13883 \\
        \textbf{Adresse:} Insterburger Straße 2, 76139 Karlsruhe \\
        \textbf{Studiengang:} Musikinformatik (HF), Musikwissenschaft (EF) \\
        \textbf{Erstleser:} Prof. Dr. Christoph Seibert \\
        \textbf{Zweitleser:} Daniel Höpfner \\
    \end{minipage}

    \vfill
    Karlsruhe, den \today
\end{titlepage}

% ------ Inhaltsverzeichnis ------
\cleardoublepage
\pagenumbering{roman}
\tableofcontents

% ------ Abbildungsverzeichnis ------
\cleardoublepage
\listoffigures
\addcontentsline{toc}{chapter}{Abbildungsverzeichnis}
\listoftables
\addcontentsline{toc}{chapter}{Tabellenverzeichnis}

% ------ Einleitung ------
\cleardoublepage
\pagenumbering{arabic}
\setcounter{page}{1}
\chapter*{Einleitung}
\addcontentsline{toc}{chapter}{Einleitung}
\setcounter{section}{0}
\renewcommand\thesection{\arabic{section}}

In der Vergangenheit gab es bereits Projekte einen Medienserver für die Bibliothek der Hochschule für Musik Karlsruhe aufzusetzen. 
Diese Projekte wurden jedoch nie abgeschlossen oder die Systeme wurden nicht dauerhaft betrieben.
Es soll einen ersten Medienserver gegeben haben, jedoch nur mit limitiererter Funktionalität, 
sodass Frederik Schroff im Jahr 2015 als Masterarbeit einen verbesserten Medienserver inklusive Datenbank aufsetzte.
Dieser ist allerdings seit einigen Jahren nicht mehr in Betrieb.
Während meiner Arbeit als Tutor in der Bibliothek, war meine offizielle Aufgabe stehts nur CDs einzulesen, zu benennen und abzuspeichern.
Diese waren anschließend aber nicht abrufbar, sodass ich anfing die Arbeit zu hinterfragen.
Nachdem ich als Praxisarbeit bereits den Digitalisierungsprozess der CDs durch die Erneuerung des dafür verwendeten Skripts verbesserte, 
möchte ich nun den Medienserver neu aufsetzen, damit die angesammelten Daten auch genutzt werden können.

Ziel ist es den Server so zu gestalten, dass er einfach zu betreiben ist und über eine benutzerfreundliche Oberfläche verfügt.
Es soll ermöglicht werden, die digitalisierten CDs damit unter Beachtung rechtlicher Rahmenbedingungen zu streamen.

\section{Zur Dokumentation}
Die Dokumentation Gliedert sich in zwei Teile, wobei der erste Teil die technischen Hintergründe beschreibt
und der zweite Teil auf die praktische Umsetzung in der Bibliothek eingeht.
Damit dient sie nicht nur dazu einen Einstieg in den Themenbereich Netzwerk und Serveradminastration zu geben, 
sondert bildet auch die Anleitung zur Nutzung und Wartung des Medienservers in der Bibliothek ab.

Im ersten Teil werden grundlegende Begriffe erläutert, 
die Entwicklung von Servern und Medienservern nachgezeichnet 
sowie deren Anwendungsbereiche dargestellt. 
Darauf aufbauend werden technische Aspekte der Serverarchitektur, 
der Administration und der Netzwerktechnik vorgestellt, 
bevor auf spezifische Eigenschaften von Medienservern eingegangen wird. 
Abschließend wird die besondere Rolle von Medienservern im 
Bibliothekskontext betrachtet. 

Der zweite Teil beschreibt die praktische Umsetzung des Projekts. 
Hier wird zunächst die Zielsetzung definiert und die notwendigen 
Voraussetzungen hinsichtlich Hard- und Software sowie des Netzwerks erläutert. 
Es folgt die detaillierte Installation und Konfiguration der 
benötigten Komponenten, die Integration in die bestehende IT-Infrastruktur 
sowie die Einrichtung der Benutzerverwaltung und Zugriffsrechte. 
Darüber hinaus werden Testverfahren und Strategien zur 
Fehlerbehebung dokumentiert. 

Den Abschluss der Arbeit bilden ein Fazit mit einer 
kritischen Reflexion des Projekts sowie ein Ausblick 
auf mögliche Weiterentwicklungen.

% ------ Theoretische Grundlagen ------
\chapter*{Theoretische Grundlagen}
\addcontentsline{toc}{chapter}{Theoretische Grundlagen}
\setcounter{section}{0}

\section{Einführung in Server und Medienserver}
Server bilden das Fundament moderner IT-Infrastrukturen.
Sie übernehmen zentrale Aufgaben bei der Bereitstellung von Diensten 
und der Verwaltung von Daten. 
Im Zusammenhang mit Medienservern steht vor allem die Speicherung, 
Organisation und Übertragung digitaler Inhalte wie Musik, 
Videos oder Bilder im Vordergrund. 

Medienserver ermöglichen es, solche Inhalte in Echtzeit zu streamen, 
ohne dass ein vollständiger Download notwendig ist. 
Ihre Entwicklung ist eng mit der allgemeinen Geschichte von Servertechnologien und Netzwerken verknüpft 
und reicht von klassischen Rechenzentren über den Aufstieg des Internets bis hin zu modernen Heim- und Cloudlösungen. 

Heute finden Medienserver Einsatz in unterschiedlichsten Bereichen - 
von der privaten Nutzung über Unternehmen bis hin zu Bibliotheken, 
die digitalisierte Bestände für ihre Nutzer zugänglich machen.

  \subsection{Begriffsdefinitionen}
  Als \emph{Server} bezeichnet man einen „Rechner, 
  der für andere in einem Netzwerk mit ihm verbundene Systeme bestimmte Aufgaben übernimmt 
  und von dem diese ganz oder teilweise abhängig sind“. \footcite{duden_server}

  In diesem Zusammenhang ist ein \emph{Netzwerk} ein Zusammenschluss von „zwei oder mehr Computern,
  die miteinander verbunden sind, um Daten elektronisch auszutauschen.“
  (Übersetzung nach \footcite{britannica_network})

  Ein \emph{Medienserver} ist eine spezialisierte Form eines Servers, 
  die darauf ausgelegt ist, digitale Medieninhalte wie Audio, Video oder Bilder zu speichern, 
  zu verwalten und über ein Netzwerk für Clients bereitzustellen.\footcite[Vgl.][S.~131 ~ff.]{steinmetz_multimedia}

  Unter \emph{Streaming} versteht man die Übertragung von Audio- bzw. Videodaten von einem Server auf einen Client, 
  wobei die Wiedergabe umgehend erfolgt.\footcite{gabler_streaming}
  Multimedia-Inhalten können so bereits während der Übertragung konsumiert werden, 
  ohne dass eine vollständige Speicherung der Daten auf dem Endgerät erforderlich ist.

  Server und Clients bilden damit die grundlegende Kommunikationsbasis in Netzwerken. 
  Medienserver stellen eine spezielle Ausprägung dar, 
  die insbesondere für die effiziente Bereitstellung von Streaming-Inhalten optimiert sind.

  \subsection{Historische Entwicklung}
  Die Entwicklung von Servern und Netzwerken ist eng mit der allgemeinen Geschichte der Computerkommunikation verknüpft. 
  Erste Formen von Rechnernetzen entstanden bereits Ende der 1950er Jahre mit dem ARPANET, 
  das als Vorläufer des heutigen Internets gilt 
  und den Grundstein für die paketorientierte Datenübertragung legte.\footcite[Vgl.][S.~45~f.]{tanenbaum_computernetworks}

  In den frühen 1970er Jahren zeigte sich, dass die bestehenden Protokolle des ARPANET nicht ausreichten, 
  um heterogene Netzwerke wie Funk- oder Satellitennetze zu integrieren. 
  Vor diesem Hintergrund entwickelten Vinton Cerf und Robert Kahn 1974 das Transmission Control Protocol (TCP), 
  das später in die heute gebräuchliche Protokollfamilie TCP/IP aufgeteilt wurde. 
  TCP/IP ermöglichte die zuverlässige Kommunikation über unterschiedliche Netzwerke hinweg 
  und bildete die Grundlage für die Interoperabilität moderner Netze.\footcite[Vgl.][S.~45]{tanenbaum_computernetworks}
  Im Jahr 1983 wurde TCP/IP im ARPANET als verbindlicher Standard eingeführt,
  was gemeinhin als Geburtsstunde des modernen Internets gilt.\footnote{Vgl. \cite[S.~2]{postel_rfc801}; \cite{britannica_tcpip}.}

  In den 1980er und 1990er Jahren etablierte sich das Client-Server-Modell als dominierendes Paradigma für den Datenaustausch. 
  Hierbei übernehmen Server die Rolle zentraler Dienstleister, 
  während Clients auf deren Ressourcen zugreifen.\footcite[Vgl.][S.~114]{kurose_networking} 
  Mit der zunehmenden Verbreitung des Internets wurden Server in Unternehmen, 
  Hochschulen und öffentlichen Institutionen zu zentralen Infrastrukturen.

  Parallel dazu entwickelte sich der Bedarf an multimedialer Datenübertragung. 
  Erste Streaming-Verfahren wie RealAudio (1995) ermöglichten die kontinuierliche Übertragung von Audioinhalten, 
  ohne dass die Daten vollständig gespeichert werden mussten. 
  Diese Technologie wurde später auf Video übertragen 
  und in standardisierte Protokolle wie Real-time Transport Protocol (RTP) überführt.\footcite[Vgl.][S.~11~ff., S.~273~ff.]{steinmetz_multimedia}

  Seit den 2000er Jahren prägen Breitbandinternet und die Verbreitung mobiler Endgeräte die Nutzung multimedialer Inhalte. 
  Parallel dazu entwickelten sich adaptive Streaming-Technologien wie MPEG-DASH (Standardisierung 2012)
  und Apple HLS (2009), die eine effiziente und bandbreitenabhängige Übertragung von Audio- 
  und Videoinhalten ermöglichen.\footcite[Vgl.]{iso_mpegdash, apple_hls}
  Medienserver sind in diesem Kontext zu zentralen Plattformen für die Speicherung und Bereitstellung digitaler Bestände geworden 
  und finden heute sowohl im privaten Umfeld als auch in Institutionen wie Hochschulen und Bibliotheken Anwendung.

  \subsection{Anwenwendungsbereiche}
  Server übernehmen zentrale Aufgaben in der IT, etwa als Datei-, Datenbank-, Web- oder E-Mail-Server. 
  Darüber hinaus kommen sie in Bereichen wie Virtualisierung, Cloud-Computing
  oder bei Sicherheitsdiensten (z.\,B. Authentifizierung, Firewalls) zum Einsatz.

  Medienserver bilden eine spezialisierte Kategorie: Sie speichern und verwalten
  digitale Audio-, Video- und Bildbestände und stellen diese über Netzwerke bereit.
  Einsatzfelder finden sich im privaten Umfeld (Streaming von Musik und Filmen),
  in Unternehmen (z.\,B. interne Schulungsvideos oder Marketingmaterial),
  im Bildungsbereich (Vorlesungsaufzeichnungen, E-Learning-Plattformen) sowie
  in Kulturinstitutionen wie Archiven und Bibliotheken, wo sie die Nutzung und
  Langzeitverfügbarkeit digitalisierter Sammlungen unterstützen.\footcite[Vgl.][S.~131~ff.]{steinmetz_multimedia}

\section{Grundlagen der Serverarchitektur}
Serverarchitekturen umfassen sowohl Hardware- als auch Softwareaspekte. 
Sie bilden die Grundlage für den Betrieb spezialisierter Systeme wie Medienserver, 
die neben klassischen Serverkomponenten auch spezielle Anforderungen an Speicher und Datenübertragung stellen.

  \subsection{Hardware- und Softwareaspekte}
  Ein Server besteht aus zentralen Hardwarekomponenten wie Prozessor, Hauptspeicher, Netzwerk- und Massenspeicherhardware. 
  Für den Dauerbetrieb sind Aspekte wie Zuverlässigkeit, Ausfallsicherheit, Energieeffizienz und Skalierbarkeit besonders wichtig. 
  Anders als bei Arbeitsplatzrechnern kommen häufig redundante Netzteile, unterbrechungsfreie Stromversorgungen, 
  spezielle Kühlungssysteme sowie redundante Netzwerkverbindungen zum Einsatz, 
  um eine kontinuierliche Verfügbarkeit zu gewährleisten.\footcite[Vgl.][S.~152541]{ahmed2021energy} 

  % Auch die Netzwerkanbindung ist von zentraler Bedeutung: 
  % Mehrport-Netzwerkkarten, redundante Switch-Anbindungen oder Load-Balancing-Verfahren 
  % stellen sicher, dass ein Server auch bei steigender Last oder im Fehlerfall 
  % funktionsfähig bleibt.\footcite[Vgl.][?]{tanenbaum_computernetworks}

  Auf der Softwareseite bilden Betriebssysteme die Grundlage für den Betrieb, 
  wobei sich stabile, sichere und gut wartbare Plattformen durchgesetzt haben. 
  Darüber hinaus sind Serverdienste (z.\,B. Web-, Datenbank- oder Streamingdienste) 
  sowie Middleware-Komponenten erforderlich, die den Zugriff von Clients ermöglichen 
  und die Kommunikation zwischen verschiedenen Anwendungen koordinieren. 
  Gerade bei Medienservern sind zudem Softwarelösungen zur effizienten Verwaltung, 
  Katalogisierung und Bereitstellung multimedialer Inhalte notwendig.

  \subsection{Betriebssysteme für Server}
  Zu den gängigsten Server-Betriebssystemen zählen insbesondere 
  Linux-Distributionen, Windows Server sowie UNIX-Derivate.
  Linux gilt als besonders verbreitet im Bereich Web- und Medienserver, 
  da es durch Stabilität, Sicherheit und Flexibilität überzeugt und 
  vor allem als bevorzugte Plattform für Webserver wie Apache dient.\footcite[Vgl.][S.~963~ff.]{nemeth_unixlinux} 
  Windows Server findet häufig Anwendung in Unternehmensumgebungen, 
  insbesondere durch die Integration mit Active Directory, 
  das als zentrales Verzeichnis- und Authentifizierungssystem eine 
  wichtige Rolle spielt.\footcite[Vgl.][S.~1154~f.]{nemeth_unixlinux}

  \subsection{Virtualisierung und Containerisierung}
  Moderne Serverarchitekturen setzen zunehmend auf Virtualisierung und Containerisierung, 
  um Hardware effizienter auszunutzen und Dienste flexibel bereitzustellen. 

  Klassische Virtualisierungslösungen wie VMware oder KVM ermöglichen die parallele Ausführung mehrerer 
  virtueller Maschinen auf einer physischen Hardware.\footcite[Vgl.][S.~1005, S.~995~f.]{nemeth_unixlinux} 

  Containerisierungstechnologien wie Docker und Kubernetes gehen darüber hinaus einen Schritt weiter, 
  indem sie Anwendungen in isolierten Umgebungen ausführen und dabei besonders ressourcenschonend sowie 
  skalierbar gestalten. Wie im Beitrag von Mao et al. (2020) hervorgehoben wird, 
  bildet „die container-basierte Virtualisierungstechnologie, 
  wie Docker und Kubernetes, die Grundlage für cloud-native Anwendungen“.\footcite{mao2020containers}

\subsection{Dateisysteme und Speicherlösungen}
Für Medienserver spielt die Wahl der Speicherarchitektur eine zentrale Rolle. 
Netzwerkspeicherlösungen wie Network Attached Storage (NAS) und Storage Area Networks (SAN) 
ermöglichen die zentrale Bereitstellung großer Datenmengen. 
NAS-Systeme stellen Speicher im Netzwerk auf Dateiebene bereit und zeichnen sich durch einfache Einrichtung, 
schnellen Datenzugriff und unkomplizierte Administration aus.\footcite[Vgl.][S.~21857]{saravanamuthu2014study} 
SANs hingegen arbeiten auf Blockebene und sind für besonders leistungsintensive Anwendungen optimiert; 
sie bieten hohe Bandbreiten, niedrige Latenzen und ermöglichen die zentrale Verwaltung großer Speicherpools.\footcite[Vgl.][S.~21858~f.]{saravanamuthu2014study}  

Moderne Speicherlösungen sind darüber hinaus auf niedrige Latenz, hohe Bandbreite und Skalierbarkeit ausgelegt. 
In experimentellen Vergleichen konnte gezeigt werden, dass SAN-Systeme bei großen Datenmengen und intensiven Workflows deutliche Leistungs- 
und Latenzvorteile gegenüber NAS haben.\footcite[Vgl.][Abschnitt~IV; Ergebnisse]{jaikar2016performance}  
NAS-Systeme dagegen bieten Dateizugriff über verbreitete Protokolle (z. B. NFS, SMB) 
und sind häufig kostengünstiger in Anschaffung und Wartung.\footcite[Vgl.][S.~21857]{saravanamuthu2014study}


Neben der Netzwerkanbindung ist Redundanz ein entscheidender Faktor: Mechanismen 
wie RAID (Redundant Array of Independent Disks) schützen vor Datenverlust durch 
Festplattenausfall, während Hot-Swapping und automatische Neusynchronisation 
die Verfügbarkeit auch im Fehlerfall erhöhen. In der klassischen Untersuchung „RAID: 
High-Performance, Reliable Secondary Storage“ wird herausgearbeitet, dass RAID-Systeme durch Striping über mehrere Festplatten 
und durch Redundanz eine signifikante Verbesserung von Leistung und Zuverlässigkeit bieten, insbesondere bei großen Datenmengen 
und paralleler Zugriffslast.\footcite[Vgl.][151 ~ff.]{chen2004raid}

\section{Serveradministration}
Die Administration eines Servers umfasst grundlegende Prozesse der Benutzerverwaltung, Wartung und Absicherung. 
Sie bildet die Voraussetzung für einen stabilen und sicheren Betrieb und ist in der Praxis oft ein kontinuierlicher Prozess. % \footcite[Vgl.][Kapitel~1.1]{nemeth_unixlinux}

  \subsection{Benutzer- und Rechteverwaltung}
  Ein zentrales Element der Serveradministration ist die Verwaltung von Benutzern und deren Zugriffsrechten. 
  In UNIX- und Linux-Systemen erfolgt die Identifikation über eindeutige Benutzerkennungen (User IDs, UIDs) 
  und Gruppenzugehörigkeiten (Group IDs, GIDs).\footcite[Vgl.][S.~176~ff.]{nemeth_unixlinux}
  Das klassische UNIX-Berechtigungsmodell unterscheidet dabei drei grundlegende Kategorien: 
  \emph{user} (Besitzer), \emph{group} (Mitglieder der zugewiesenen Gruppe) und \emph{others} (alle übrigen Nutzer). 
  Für jede dieser Kategorien lassen sich Lese- (read, r), Schreib- (write, w) und Ausführungsrechte (execute, x) festlegen.\footcite[Vgl.]{wikipedia_dateisystemrechte}

  Zentral ist zudem die Trennung zwischen normalen Benutzerkonten und dem privilegierten \emph{Superuser} (\texttt{root}), 
  der uneingeschränkten Zugriff auf das gesamte System besitzt. 
  Viele moderne Distributionen nutzen anstelle direkter Root-Anmeldungen das \texttt{sudo}-Kommando, 
  das einzelnen Benutzern temporär administrative Rechte verleiht und gleichzeitig Aktionen protokolliert.\footcite[Vgl.][S.~112~ff.]{nemeth_unixlinux}

  Erweiterte Mechanismen wie \emph{Access Control Lists (ACLs)} ermöglichen eine feinere Abstufung der Berechtigungen, 
  indem sie Zugriffsrechte für mehrere Benutzer und Gruppen individuell definieren.\footcite[Vgl.][S.~159~ff.]{nemeth_unixlinux} 
  In einigen Systemen wie Solaris findet darüber hinaus eine rollenbasierte Zugriffskontrolle (\emph{Role-Based Access Control, RBAC}) Anwendung. 
  Dieses Konzept weist Rechte nicht mehr einzelnen Benutzern, sondern Rollen zu, die wiederum von Benutzern übernommen werden können. 
  Dadurch lassen sich administrative Aufgaben gezielt delegieren, ohne umfassende Superuser-Rechte vergeben zu müssen.\footcite[Vgl.][S.~108]{nemeth_unixlinux}

  \subsection{Dienste und Prozesse}
  Die Funktionsfähigkeit eines Servers basiert wesentlich auf Prozessen und Diensten. 
  Während Prozesse allgemein laufende Programme im Betriebssystem darstellen, 
  sind Dienste spezielle Hintergrundprozesse, die in UNIX- und Linux-Systemen 
  traditionell als \emph{daemons} bezeichnet werden.\footcite[Vgl.]{wikipedia_daemon}  

  Die Verwaltung dieser Dienste erfolgt über das \emph{init}-System, 
  das beim Bootvorgang automatisch Prozesse startet und kontrolliert. 
  Dabei kommen distributionsspezifische Startskripte zum Einsatz.\footcite[Vgl.][S.~88~ff.]{nemeth_unixlinux}  

  In vielen modernen Linux-Distributionen hat sich \emph{systemd} etabliert, 
  das Dienste parallelisiert starten kann und erweiterte Funktionen wie Abhängigkeitsmanagement 
  sowie integriertes Logging bietet.\footcite[Vgl.]{wikipedia_systemd}   

  \subsection{Monitoring und Logging}
  Für den Betrieb von Servern ist die kontinuierliche Überwachung essenziell. 
  Monitoring umfasst sowohl die Ressourcennutzung (CPU, RAM, Festplatten, Netzwerk) als auch die Erreichbarkeit zentraler Dienste. 
  Hierfür stehen je nach System Werkzeuge wie \texttt{top} (Linux), \texttt{topas} (AIX) oder \texttt{prstat} (Solaris) zur Verfügung, 
  die eine regelmäßig aktualisierte Übersicht über aktive Prozesse und deren Ressourcennutzung bieten.\footcite[Vgl.][S.~133]{nemeth_unixlinux}
  Darüber hinaus ermöglichen sie Administratoren auch Eingriffe, 
  etwa durch das Senden von Signalen oder das Anpassen der Priorität von Prozessen.\footcite[Vgl.][S.~134]{nemeth_unixlinux}

  Logging erfolgt primär über das \emph{Syslog}-Framework, das Ereignisse zentral erfasst und in Logdateien strukturiert speichert.\footcite[Vgl.][S.~344~ff.]{nemeth_unixlinux}  
  Eine strukturierte Protokollauswertung ist entscheidend, um Fehlerquellen und sicherheitsrelevante Vorfälle nachvollziehen zu können. 
  Moderne Systeme ermöglichen zudem die Weiterleitung von Logs an zentrale Server oder die Integration in Analyseplattformen, 
  um eine konsolidierte Überwachung zu gewährleisten.\footcite[Vgl.][S.~348]{nemeth_unixlinux}

  \subsection{Backup- und Recovery-Strategien}
  Datenverluste durch Hardwareausfälle oder Benutzerfehler gehören zu den größten Risiken im Serverbetrieb. 
  Daher sind regelmäßige Backups sowie erprobte Wiederherstellungsstrategien unverzichtbar. 
  Gängige Verfahren sind \emph{inkrementelle} und \emph{differenzielle Backups}. 
  Bei inkrementellen Sicherungen werden jeweils nur die seit der letzten Sicherung 
  geänderten Daten gespeichert, während differenzielle Backups stets alle Änderungen 
  seit der letzten Vollsicherung erfassen.\footcite[Vgl.][S.~305~f.]{nemeth_unixlinux}  
  Diese Methoden reduzieren den Aufwand und Speicherbedarf gegenüber Vollsicherungen erheblich. 

  Für kritische Systeme werden zusätzlich \emph{Offsite-Backups} eingesetzt. 
  Das bedeutet, dass Kopien der Daten an einem geographisch getrennten Standort gespeichert werden, 
  sei es durch das Versenden physischer Medien oder durch Übertragung an entfernte Speicher/Cloud-Dienste. 
  Diese Maßnahme schützt vor lokalen Katastrophen wie Brand oder Naturereignissen 
  und ermöglicht eine schnelle Wiederaufnahme des Betriebs, wenn die Hauptanlage nicht nutzbar ist.\footcite[Vgl.]{wikipedia_offsite_data_protection}  

  \subsection{Sicherheitsaspekte}
  Die Absicherung von Servern erfordert ein mehrschichtiges Konzept, 
  das organisatorische, technische und prozessuale Maßnahmen umfasst.
  Ein ganzheitliches Sicherheitskonzept, das möglichst viele der folgenden grundlegenden Aspekte enthält ist unverzichtbar, 
  um Server vor Angriffen und Ausfällen zu schützen und die Verfügbarkeit kritischer Dienste sicherzustellen.
  \\
  \newline
  \textbf{Netzwerkschutz}:  
  Ein zentraler Bestandteil der Serversicherheit ist der Schutz der Netzwerkschnittstellen. 
  Hierzu werden Firewalls eingesetzt, um eingehenden und ausgehenden Datenverkehr anhand von Regeln zu kontrollieren. 
  Klassische Paketfilter analysieren Header-Informationen wie Quell- und Zieladresse oder Ports und können so unerwünschte Verbindungen blockieren.\footcite[Vgl.][S.~932~ff.]{nemeth_unixlinux}  
  \\
  \newline
  \textbf{Verschlüsselung}:  
  Um die Vertraulichkeit und Integrität der Kommunikation zu gewährleisten, werden Verschlüsselungstechniken eingesetzt. 
  Transport Layer Security (TLS/SSL) schützt Datenströme im Internet, Virtual Private Networks (VPNs) verschlüsseln den gesamten Datenverkehr zwischen Standorten, 
  und Secure Shell (SSH) ermöglicht eine abgesicherte Fernadministration.\footcite[Vgl.][S.~801, S.~971, S.~926~ff., S.~942]{nemeth_unixlinux}  
  \\
  \newline
  \textbf{Benutzer- und Rechteverwaltung}:  
  Ein konsequentes Berechtigungsmanagement stellt sicher, dass Benutzer nur Zugriff auf die Ressourcen haben, die sie tatsächlich benötigen. 
  Dazu gehören sichere Passwörter, Mechanismen wie \emph{Password Aging} (zeitliche Begrenzung der Passwortgültigkeit) 
  und die Vergabe von Rechten nach dem Prinzip des geringsten Privilegs. 
  So wird verhindert, dass kompromittierte Accounts zu weitreichenden Sicherheitsproblemen führen.\footcite[Vgl.][S.~905~ff.]{nemeth_unixlinux}  
  \\
  \newline
  \textbf{Systemhärtung}:  
  Viele Systeme sind in der Standardkonfiguration mit unnötigen Diensten ausgestattet, die zusätzliche Angriffsflächen bieten. 
  Systemhärtung bedeutet, diese Dienste konsequent zu deaktivieren und Konfigurationen sicherheitsorientiert vorzunehmen. 
  Damit sinkt die Wahrscheinlichkeit, dass Angreifer über Fehlkonfigurationen oder selten genutzte Software ins System eindringen können.\footcite[Vgl.][S.~902]{nemeth_unixlinux}
  \\  
  \newline
  \textbf{Updates und Patching}:  
  Die meisten erfolgreichen Angriffe erfolgen über bekannte, aber nicht geschlossene Schwachstellen. 
  Daher ist ein zeitnahes Einspielen von Patches für Betriebssystem und Anwendungssoftware unerlässlich. 
  Ein strukturierter Patch-Management-Prozess reduziert das Risiko signifikant.\footcite[Vgl.][S.~901]{nemeth_unixlinux}  
  \\
  \newline
  \textbf{Intrusion Detection und Monitoring}:  
  Intrusion Detection Systeme (IDS) überwachen den Datenverkehr oder Host-Systeme auf verdächtige Aktivitäten. 
  Intrusion Prevention Systeme (IPS) gehen noch einen Schritt weiter und können erkannte Angriffe automatisch blockieren. 
  Beispiele sind Snort (Netzwerk-IDS) oder OSSEC (Host-basiertes IDS). 
  In Kombination mit einer kontinuierlichen Log-Analyse ermöglichen diese Werkzeuge eine frühzeitige Erkennung von Angriffen.\footcite[Vgl.][S.~918~ff.]{nemeth_unixlinux} 
  \\ 
  \newline
  \textbf{Backups und Recovery}:  
  Auch wenn alle präventiven Maßnahmen ergriffen werden, lassen sich Vorfälle nicht vollständig verhindern. 
  Regelmäßige Backups sind daher ein essenzielles Element der Sicherheit, da sie eine Wiederherstellung nach Angriffen oder Ausfällen ermöglichen. 
  Besonders im Kontext von Ransomware oder Datenmanipulation sind getestete Recovery-Strategien unverzichtbar.\footcite[Vgl.][S.~903]{nemeth_unixlinux} 
  \\ 
  \newline
  \textbf{Proaktives Sicherheitsmanagement}:  
  Technische Maßnahmen reichen allein nicht aus. 
  Ein umfassendes Sicherheitskonzept verlangt nach klar definierten Richtlinien, kontinuierlichen Audits und einem hohen Maß an Wachsamkeit. 
  Administratoren sollten regelmäßig die Wirksamkeit der Maßnahmen prüfen und neue Bedrohungslagen aktiv in die Planung einbeziehen. 
  So wird Sicherheit zu einem fortlaufenden Prozess und nicht zu einem einmaligen Projekt.\footcite[Vgl.][S.~901, S.~905]{nemeth_unixlinux}  

\section{Netzwerktechnik für Medienserver}
Netzwerke bilden die Grundlage für den Zugriff auf Medienserver. 
Dieser Abschnitt erläutert zentrale Konzepte, Protokolle sowie Leistungs- und Sicherheitsaspekte, 
die für den effizienten Betrieb relevant sind.  

  \subsection{Grundlagen der Netzwerktechnik}  
  Die Kommunikation in Netzwerken basiert auf dem \emph{TCP/IP}-Protokollstapel. 
  \emph{IP} (\emph{Internet Protocol}) ist für die Adressierung und Weiterleitung von Paketen zuständig 
  und bildet die Grundlage für die Kommunikation in paketvermittelten Netzwerken.\footcite[Vgl.][S.~438]{tanenbaum_computernetworks}  
  Darüber hinaus sorgen \emph{TCP} (\emph{Transmission Control Protocol}) und \emph{UDP} (\emph{User Datagram Protocol}) 
  auf der Transportschicht für den eigentlichen Datentransport. 
  TCP stellt eine verbindungsorientierte, zuverlässige Übertragung mit Fehlerkorrektur und Flusskontrolle bereit, 
  während UDP ein verbindungsloses, leichtgewichtiges Protokoll ist, 
  das insbesondere für zeitkritische Anwendungen wie Audio- und Videostreaming eingesetzt wird.\footcite[Vgl.][S.~228]{kurose_networking}
 
  Dienste werden über \emph{Ports} identifiziert, etwa Port~80 für HTTP oder Port~443 für HTTPS.\footcite[Vgl.][S.~554]{tanenbaum_computernetworks}  
  Für die Namensauflösung sorgt das Domain Name System (DNS), 
  das menschenlesbare Hostnamen in IP-Adressen übersetzt 
  und somit die Grundlage für jede netzwerkbasierte Medienübertragung bildet.\footcite[Vgl.][S.~611~f.]{tanenbaum_computernetworks}  

  \subsection{Streaming-Protokolle} 
  Zur Übertragung von Multimedia-Inhalten existieren verschiedene Protokolle. 
  Die wichtigesten werden im Folgenden vorgestellt.  
  \\
  \newline
  \textbf{HTTP (Hypertext Transfer Protocol):}
  HTTP ist ein Anwendungsprotokoll auf der Anwendungsschicht und bildet das Herzstück des World Wide Web. 
  Es wird in einem Client- und einem Server-Programm implementiert, die über den Austausch von HTTP-Nachrichten kommunizieren. 
  Diese Nachrichten sind nach einem standardisierten Format (RFC 1945, RFC 2616) definiert und regeln die Interaktion zwischen Webbrowser und Webserver.\footcite[Vgl.][S.~126]{kurose_networking} 
  HTTP ist dabei ein \emph{zustandsloses} Protokoll, was bedeutet, dass der Server keine Informationen über vorherige Anfragen speichert. 
  Jede Anfrage wird unabhängig behandelt, wodurch HTTP besonders einfach und skalierbar ist.\footcite[Vgl.][S.~128]{kurose_networking}   
  \\
  \newline
  \textbf{RTP (Real-Time Transport Protocol):}  
  RTP transportiert Audio- und Videodaten meist über \emph{UDP (User Datagram Protocol)}. 
  Es ist speziell für Echtzeitanwendungen optimiert und unterstützt Mechanismen zur 
  Synchronisation verschiedener Medienstöme (z.\,B. Audio und Video) 
  sowie zur Kompensation von Jitter, der durch schwankende Paketlaufzeiten entsteht.\footcite[Vgl.][S.~546~ff.]{tanenbaum_computernetworks}   
  \\
  \newline
  \textbf{RTSP (Real-Time Streaming Protocol):}  
  RTSP ist ein Steuerungsprotokoll, das Befehle wie \emph{Play}, \emph{Pause} oder \emph{Seek} ermöglicht. 
  Es wird häufig zusammen mit dem \textbf{RTP (Real-Time Transport Protocol)} verwendet, 
  das die eigentliche Datenübertragung übernimmt.\footcite[Vgl.][S.~638~f.]{kurose_networking}  
  \\
  \newline
  \textbf{HLS (HTTP Live Streaming):}
  HLS ist ein von Apple entwickeltes Streaming-Protokoll, das in \emph{RFC 8216} standardisiert ist.
  Es basiert auf der Idee, Medieninhalte in kleine Segmente (Chunks) zu zerlegen, die sequenziell über HTTP übertragen werden.
  Ein Manifest (Playlist) beschreibt die Abfolge dieser Segmente, wodurch auch unterschiedliche Qualitätsstufen bereitgestellt werden können.
  Dies ermöglicht \emph{adaptives Streaming}, bei dem der Client dynamisch zwischen verschiedenen Bitraten und Auflösungen wechseln kann,
  um Schwankungen in der Netzwerkbandbreite auszugleichen.\footcite[Vgl.][siehe HTTP Live Streaming Overview]{rfc8216}
  Dank der Nutzung von HTTP ist HLS besonders kompatibel mit bestehenden Infrastrukturen wie Caches und Content Delivery Networks (CDNs).\footcite[Vgl.][]{stockhammer2011dash}
  \\
  \newline
  \textbf{MPEG-DASH (Dynamic Adaptive Streaming over HTTP):}
  MPEG-DASH ist ein von der MPEG-Gruppe entwickelter Standard für adaptives Multimedia-Streaming über HTTP.
  Das Grundprinzip besteht darin, dass Multimedia-Inhalte in kleine Segmente zerlegt werden, die über herkömmliche HTTP-Server bereitgestellt werden.
  Der Client entscheidet dynamisch, welche Segmente er anfordert, um sich an schwankende Netzwerkbedingungen und Geräteeigenschaften anzupassen.\footcite[Vgl.][S.~1~ f.]{stockhammer2011dash}
  Dadurch kombiniert DASH die weite Verbreitung von HTTP-Infrastrukturen mit der Möglichkeit eines qualitativ stabilen Medienkonsums auch unter variablen Bandbreitenbedingungen.
    
  \subsection{Leistungsanforderungen}  
  Streaming-Anwendungen stellen hohe Anforderungen an die Netzwerkinfrastruktur. 
  Neben ausreichender \textbf{Bandbreite} ist vor allem geringe \textbf{Latenz} entscheidend, 
  insbesondere bei Live-Übertragungen oder interaktiven Anwendungen. 
  Eine wesentliche Rolle spielt außerdem die \textbf{Pufferung}, 
  die Jitter (Schwankungen in der Paketlaufzeit) ausgleichen soll. 
  Typische Verfahren sind Pre-Buffering und adaptive Puffergrößen.\footcite[Vgl.][S.~697~ff.]{tanenbaum_computernetworks}  

  \subsection{Qualität und Sicherheit}  
  Die Sicherstellung einer konstanten Übertragungsqualität erfordert \textbf{Quality of Service (QoS)}-Mechanismen.  
  QoS bezeichnet Techniken, die Netzwerkressourcen gezielt steuern, um die Anforderungen von Multimedia-Anwendungen zu erfüllen.\footcite[Vgl.][S.~9~ff.]{steinmetz_multimedia}  
  Im Folgenden werden einige gängige QoS-Mechanismen vorgestellt: 
  \\
  \newline
  \textbf{Traffic Shaping:}  
  Verfahren wie \emph{Token Bucket} oder \emph{Leaky Bucket} regulieren die Burstartigkeit von Datenströmen, indem sie den Datenfluss glätten und Spitzenlasten abfangen.  
  Dadurch wird ein gleichmäßigerer Durchsatz erreicht, der insbesondere für kontinuierliche Audio- und Videoübertragungen wichtig ist.\footcite[Vgl.][S.~61~f.]{steinmetz_multimedia}  
  \\
  \newline
  \textbf{Rate Control und Scheduling:}  
  Kontrollmechanismen wie \emph{Fair Queueing}, \emph{Virtual Clock} oder \emph{Delay Earliest-Due-Date} sorgen dafür, 
  dass Bandbreiten fair aufgeteilt und Verzögerungen minimiert werden.  
  Zugleich helfen sie, Jitter auszugleichen und zeitkritische Datenströme zu priorisieren.\footcite[Vgl.][S.~62~f.]{steinmetz_multimedia}  
  \\
  \newline
  \textbf{Resource Reservation:}  
  Um Paketverluste und Verzögerungen zu vermeiden, können Bandbreiten, Puffer und andere Ressourcen im Voraus reserviert werden.  
  Dies kann pessimistisch (Worst-Case) oder optimistisch (Durchschnittswert) erfolgen und garantiert so Mindestqualitäten für Multimediadienste.\footcite[Vgl.][S.~52~f.]{steinmetz_multimedia}  
  \\
  \newline
  \textbf{Admission Control:}  
  Bevor eine neue Verbindung zugelassen wird, prüft das Netzwerk, ob genügend Ressourcen vorhanden sind.  
  Fehlen diese, wird die Anfrage abgelehnt, um eine Überlastung zu verhindern und die Qualität bestehender Verbindungen nicht zu beeinträchtigen.\footcite[Vgl.][S.~50~f.]{steinmetz_multimedia}  
  \\
  \newline
  \textbf{Error Control:}  
  Fehlererkennungs- und Fehlerkorrekturverfahren (z.\,B. FEC - Forward Error Correction) sind essenziell, 
  um trotz Paketverlusten eine akzeptable Qualität sicherzustellen.  
  Dabei können Redundanzdaten eingesetzt werden, die eine Rekonstruktion verlorener Informationen ermöglichen.\footcite[Vgl.][S.~68]{steinmetz_multimedia}  
  \\
  \newline  
  Aspekte der Sicherheit, die beim Betrieb eines Medienservers berücksichtigt werden müssen,
  wurden im Abschnitt „Serveradministration“ unter „Sicherheitsaspekte“ bereits beschrieben. 
    
\section{Spezifisches zu Medienservern}
Medienserver unterscheiden sich durch Software, Formate und rechtliche Rahmenbedingungen. Dieser Abschnitt stellt relevante Systeme und Standards vor.

  \subsection{Typische Medienserver-Software}
  Plex, Jellyfin, Emby, Kodi, VLC-Streaming, Icecast und DLNA-basierte Systeme.

  \subsection{Datenformate und Standards}
\begin{itemize}
    \item Audioformate: MP3, FLAC, AAC, WAV
    \item Containerformate: MKV, MP4
    \item Metadatenstandards: ID3, Dublin Core (insbesondere im Bibliothekskontext)
\end{itemize}

  \subsection{Rechtsfragen}
    \begin{itemize}
        \item Lizenzen und Lizenzmodelle
        \item Urheberrechtliche Rahmenbedingungen
        \item Bibliotheksrecht im Hochschulkontext
    \end{itemize}

\section{Medienserver im Bibliothekskontext}
Der Einsatz von Medienservern in Bibliotheken eröffnet neue Möglichkeiten für den Zugriff auf digitalisierte Bestände, stellt jedoch auch besondere Anforderungen an Recht, Technik und Nachhaltigkeit.

  \subsection{Digitalisierung von Beständen}
  Beispiel: Umwandlung und Speicherung von Audio-CDs in digitale Formate.

  \subsection{Zugriff und Rechteverwaltung}
  Einschränkungen des Zugriffs, etwa nur im Hochschulnetz oder über VPN.

  \subsection{Nachhaltigkeit und Langzeitarchivierung}
  Strategien zur dauerhaften Sicherung digitaler Medien.

  \subsection{Lokale vs.\ Cloud-basierte Lösungen}
  Vergleich der Vor- und Nachteile unterschiedlicher Implementierungsansätze.

% ------ Praktische Umsetzung ------
\chapter*{Praktische Umsetzung}
\addcontentsline{toc}{chapter}{Praktische Umsetzung}
\setcounter{section}{0}

\section{Zielsetzung}
  \subsection{Funktionalität}
  \subsection{Benutzerfreundlichkeit}
  \subsection{Wartbarkeit}
  \subsection{Sicherheit}
  \subsection{Rechtliche Rahmenbedingungen}
\section{Vorraussetzungen}
  \subsection{Hardware}
  \subsection{Software}
  \subsection{Netzwerk}
  \subsection{Rechtliche Rahmenbedingungen}
\section{Installation und Konfiguration}  
Die Installation und Konfiguration der zentralen Softwarekomponenten stellt die Grundlage für den zuverlässigen und sicheren Betrieb des Medienservers dar.
Nun werden die benötigten Werkzeuge und Dienste vorgestellt und ihre Einrichtung anhand einer praxisorientierten Schritt-für-Schritt-Anleitung beschrieben.
Damit soll der Aufbau des Medienservers in der Bibliothek nachvollziehbar und reproduzierbar gemacht werden.

  \subsection{Ubuntu Server}  
  Ubuntu Server ist eine weit verbreitete Linux-Distribution, die durch ihre Stabilität, breite Community-Unterstützung und regelmäßige Sicherheitsupdates überzeugt.  
  Das aktuelle Installations-ISO kann von der offiziellen Webseite heruntergeladen werden: \url{https://ubuntu.com/download/server}.  
  Nach dem Download wird das Image auf einen USB-Stick geschrieben (z.\,B. mit \texttt{Rufus} oder \texttt{dd} unter Linux).  
  Dabei ist zu beachten, dass der Stick keine wichtigen Daten enthält, da dieser vollständig überschrieben wird, und eine Mindestgröße von 5\,GB haben sollte.    
  Um die Installation zu starten, wird der Stick angeschlossen und über das Boot-Menü (Taste \texttt{F12}, \texttt{Esc} oder \texttt{Del}, abhängig vom Hersteller) ausgewählt.  
  Die textbasierte Installationsroutine führt anschließend durch Partitionierung, Netzwerkkonfiguration und die Einrichtung eines Administratorkontos.  
  Weitere informationen sind in der offiziellen Dokumentation verfügbar: \url{https://ubuntu.com/server/docs/installation}.

  \subsection{Docker}  
  Docker ist eine Container-Plattform, die Anwendungen in isolierten Umgebungen ausführt.  
  Die offizielle Installationsanleitung ist verfügbar unter: \url{https://docs.docker.com/engine/install/}.  
  Unter Ubuntu kann Docker wie folgt installiert werden.  
  (Vor der Ausführung des Codes sollte dieser stehts geprüft werden. 
  Die aktuellen Befehle sind in der offiziellen Dokumentation unter der zuvor genannter URL verfügbar.)
  \begin{enumerate}
    \item Einrichten des Docker-Repositories:
    \begin{minted}[breaklines, linenos]{bash}
# Add Docker's official GPG key:
sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc

# Add the repository to Apt sources:
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update
    \end{minted} 

    \item Installation der Docker Packete:
    \begin{minted}[breaklines, linenos]{bash}
sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
    \end{minted}

    \item Checks:
    \begin{minted}[breaklines, linenos]{bash}
# Verifiziere, dass Docker läuft
sudo systemctl status docker

# Testen der Installation mit dem Hello-World Container
sudo docker run hello-world
    \end{minted} 
  
    \item Nutzung:
    Nach der Installation kann Docker Compose für die Verwaltung von Containern genutzt werden.  
    Dafür ist es sehr nützlich folgende Befehle, die im Verzeichnis ausgeführt werden, 
    in dem sich die \texttt{docker-compose.yml}-Datei befindet, zu kennen:

    \begin{minted}[breaklines, linenos]{bash}
# Container erstellen und im Hintergrund starten
sudo docker compose up -d

# Container starten und stoppen
sudo docker compose start
sudo docker compose stop

# Änderungen übernehmen (z.B. nach Anpassung der Compose-Datei)
sudo docker compose up -d --build

# Container-Status überprüfen
sudo docker compose ps
sudo docker ps

# Container beenden und entfernen
sudo docker compose down
    \end{minted}
  \end{enumerate}

  \subsection{nginx}  
  \emph{nginx} ist ein moderner Webserver und Reverse Proxy, der sich durch hohe Performance auszeichnet.  
  Die offizielle Website bietet Installationshinweise und Downloads: \url{https://nginx.org/en/download.html}.  
  Unter Ubuntu kann nginx direkt über die Paketverwaltung installiert werden:

    \begin{minted}[breaklines, linenos]{bash}
# Paketliste aktualisieren
sudo apt update

# nginx installieren
sudo apt install nginx -y

# nginx starten und beim Systemstart aktivieren
sudo systemctl enable --now nginx

# Status überprüfen
sudo systemctl status nginx

# Test im Browser oder mit curl (sollte "Welcome to nginx!" zurückgeben)
curl http://localhost
  \end{minted}  

  Die Konfiguration erfolgt über Dateien im Verzeichnis \texttt{/etc/nginx/sites-available/}, 
  die durch Symlinks nach \texttt{/etc/nginx/sites-enabled/} aktiviert werden. 

  \subsection{Navidrome}  
  Navidrome ist ein leichtgewichtiger Musikserver, der als Docker-Container besonders einfach bereitgestellt werden kann.  
  Die offizielle Projektseite mit Anleitungen und Docker-Images befindet sich unter: \url{https://www.navidrome.org/docs/}.  
  Ein typisches \texttt{docker-compose.yml}-Beispiel für Navidrome sieht folgendermaßen aus:  
  \begin{verbatim}
  version: "3"
  services:
    navidrome:
      image: deluan/navidrome:latest
      restart: unless-stopped
      ports:
        - "4533:4533"
      volumes:
        - "./data:/data"
        - "./music:/music:ro"
  \end{verbatim} 

  \subsection{SSH}  
  \emph{Secure Shell (SSH)} ist das zentrale Werkzeug für den sicheren Fernzugriff auf den Server.  
  Der SSH-Server kann unter Ubuntu bereits bei der Installation aktiviert oder nachträglich installiert werden:  
  \begin{verbatim}
  sudo apt install openssh-server
  sudo systemctl enable --now ssh
  \end{verbatim}  
  Der Zugriff erfolgt dann von einem Client aus über:  
  \begin{verbatim}
  ssh benutzername@server-ip
  \end{verbatim}  
  Die offizielle Dokumentation befindet sich unter \url{https://www.openssh.com/}.  
  Für erhöhte Sicherheit wird empfohlen, die Passwort-Authentifizierung zu deaktivieren und stattdessen SSH-Schlüssel zu verwenden.\footcite[Vgl.][Kapitel~22, S.~926~ff.]{nemeth_unixlinux}  

  \subsection{UFW}  
  Die \emph{Uncomplicated Firewall (UFW)} dient zur einfachen Verwaltung der Firewall-Regeln.  
  UFW ist in den Ubuntu-Repositories enthalten und kann wie folgt installiert und aktiviert werden:  
  \begin{verbatim}
  sudo apt install ufw
  sudo ufw enable
  \end{verbatim}  
  Anschließend lassen sich Regeln hinzufügen, z.\,B. um SSH und HTTPS freizuschalten:  
  \begin{verbatim}
  sudo ufw allow 22/tcp
  sudo ufw allow 443/tcp
  \end{verbatim}  
  Alle weiteren Ports bleiben standardmäßig blockiert.  
  Offizielle Informationen sind in der Ubuntu-Dokumentation verfügbar: \url{https://help.ubuntu.com/community/UFW}.\footcite[Vgl.][Kapitel~22, S.~932~ff.]{nemeth_unixlinux}  

\section{Integration in die bestehende IT-Infrastruktur}
  \subsection{Netzwerk-Anbindung}  
  \subsection{Datenbank anbinden}
    \subsubsection{Datenstruktur}
    Benennungskonvention
  \subsubsection{Dateiformate}
  \subsubsection{Metadaten}
    \begin{itemize}
      \item ID3-Tags
      \item Vorbis Comments
      \item FLAC-Metadaten
      \item MusicBrainz
    \end{itemize}
  \subsubsection{Datenverwaltung}
    Datenpflege
    Backup-Strategie
  \subsubsection{Datenquelle}
    Skript zur Digitalisierung
    Skript zur Metadatenanreicherung
    Externe Quellen
  \subsubsection{Datenimport}
\section{Benutzerverwaltung und Zugriffsrechte}
  \subsection{Nutzergruppen definieren}
\section{Testen und Fehlerbehebung}
  \subsection{Funktionstests}
  \subsection{Problemlösung}   


\chapter*{Fazit}
\addcontentsline{toc}{chapter}{Fazit}
\setcounter{section}{0}
% Fazit folgt ...

\section{Ausblick}
% Ausblick folgt ...}

% ------ Notizen (am Ende entfernen!) ------
\section{Notizen}

\begin{enumerate}
  \item Server-Setup
    \begin{itemize}
      \item Rechner mit Ubuntu (24.04.3 LTS, da längerer Support) als Betriebssystem aufsetzen.
        \begin{itemize}
          \item Download von \url{https://ubuntu.com/download/server} auf USB-Stick
          \item Stick einstecken, Rechner booten und Installation starten
            \begin{itemize}
              \item dafür beim Anschalten des Rechners \texttt{Shift} drücken
              \item darauf achten, dass der Rechner in Zukunft nicht über USB bootet
              \item Rechner per LAN-Kabel mit dem Netzwerk verbinden
            \end{itemize}
        \end{itemize}

      \item Docker installieren
        \begin{itemize}
          \item Quickinstall:
          \begin{minted}[linenos]{bash}
sudo apt update
sudo apt install docker.io
sudo systemctl start docker
sudo systemctl enable docker
          \end{minted}

          \item Von Docker-Webseite (\url{https://docs.docker.com/engine/install/ubuntu/}):
          \begin{minted}[breaklines, linenos]{bash}
# Add Docker's official GPG key:
sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc

# Add the repository to Apt sources:
echo \
"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
$(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | \
sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update
          \end{minted}

          \item Test mit:
          \begin{minted}[linenos]{bash}
sudo docker run hello-world
          \end{minted}
        \end{itemize}
    \end{itemize}

  \item Auswahl und Installation der Medienserver-Software
    \begin{itemize}
      \item Hier kommen die Softwareoptionen rein
      \item Installationsschritte …
    \end{itemize}

  \item Integration mit der bestehenden IT-Infrastruktur
    \begin{itemize}
      \item Netzwerk-Anbindung
      \item Datenbanken anbinden …
    \end{itemize}

  \item Benutzerverwaltung und Zugriffsrechte
    \begin{itemize}
      \item Nutzergruppen definieren
      \item Rechteverwaltung testen …
    \end{itemize}

  \item Testen und Fehlerbehebung
    \begin{itemize}
      \item Funktionstests
      \item Lasttests
      \item Bugfixing dokumentieren …
    \end{itemize}
\end{enumerate}
\newpage

\chapter*{Literaturverzeichnis}
\addcontentsline{toc}{chapter}{Literaturverzeichnis}
\printbibliography[heading=none]

\end{document}
